{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import math\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the parent directory (where utils.py is located) to sys.path to ensure utils module is found\n",
    "utils_path = os.path.abspath(os.path.join(os.getcwd(), \"../../Utils/\"))\n",
    "sys.path.append(utils_path)\n",
    "\n",
    "# Import utility functions from the utils module\n",
    "from utils import (\n",
    "    color_difference,\n",
    "    collect_text_nodes,\n",
    "    count_all_descendants,\n",
    "    count_chars_to_end,\n",
    "    get_center_of_weight\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "semantic_model = SentenceTransformer('all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "body_width = None\n",
    "\n",
    "def extract_semantic_features(node, text_nodes_with_content):\n",
    "    \"\"\"\n",
    "    Calculate the semantic features from the nearest text node\n",
    "    \n",
    "    Args:\n",
    "    node : Current node being processed\n",
    "    text_nodes_with_content : List of text nodes with their x, y coordinates and text content\n",
    "    \"\"\"\n",
    "    if not text_nodes_with_content:\n",
    "        return {\n",
    "            \"nearest_text_semantic_vector\": [0] * 384,  # Default zero vector\n",
    "            \"nearest_text_semantic_distance\": 9999999\n",
    "        }\n",
    "    \n",
    "    # Get current node's center coordinates\n",
    "    node_data = node.get(\"node\", {})\n",
    "    x = node_data.get(\"x\", 0) + node_data.get(\"width\", 0) / 2\n",
    "    y = node_data.get(\"y\", 0) + node_data.get(\"height\", 0) / 2\n",
    "    \n",
    "    # Calculate Euclidean distances to all text nodes and find the nearest\n",
    "    min_distance = float('inf')\n",
    "    nearest_text_node = None\n",
    "    \n",
    "    for text_node in text_nodes_with_content:\n",
    "        tx, ty = text_node['x'], text_node['y']\n",
    "        distance = math.sqrt((x - tx)**2 + (y - ty)**2)\n",
    "        \n",
    "        if distance < min_distance:\n",
    "            min_distance = distance\n",
    "            nearest_text_node = text_node\n",
    "    \n",
    "    # If a nearest text node is found, get its semantic embedding\n",
    "    if nearest_text_node and nearest_text_node.get('text'):\n",
    "        # Generate semantic embedding for the text\n",
    "        semantic_vector = semantic_model.encode(nearest_text_node['text'])\n",
    "        \n",
    "        return {\n",
    "            \"nearest_text_semantic_vector\": semantic_vector.tolist(),  # Convert to list for JSON serialization\n",
    "            \"nearest_text_semantic_distance\": min_distance\n",
    "        }\n",
    "    \n",
    "    # Fallback if no meaningful text is found\n",
    "    return {\n",
    "        \"nearest_text_semantic_vector\": [0] * 384,  # Default zero vector\n",
    "        \"nearest_text_semantic_distance\": 9999999\n",
    "    }\n",
    "\n",
    "def extract_features(node, depth=0, parent_tag=None, sibling_count=0, parent_tag_html=None, prev_sibling_tag=None,parent_height=0, parent_bg_color=None, text_nodes=None):\n",
    "    global body_width\n",
    "    # First pass: Collect text nodes if not provided\n",
    "    if text_nodes is None:\n",
    "        text_nodes = collect_text_nodes(node)\n",
    "    \n",
    "    \n",
    "    features = []\n",
    "    \n",
    "    tag = node.get(\"tag\", \"\")\n",
    "    node_data = node.get(\"node\", {})\n",
    "    node_type = str(node_data.get(\"type\", \"\"))\n",
    "\n",
    "    text = node_data.get(\"characters\", \"\")\n",
    "    text_length = len(text)\n",
    "    word_count = len(text.split()) if text else 0\n",
    "    contains_number = any(ch.isdigit() for ch in text)\n",
    "    contains_special_chars = any(not ch.isalnum() and not ch.isspace() for ch in text)\n",
    "    \n",
    "    children = node.get(\"children\", [])\n",
    "    num_direct_children = len(children)\n",
    "    is_leaf = 1 if num_direct_children == 0 else 0\n",
    "    \n",
    "    # Initialize child tag features\n",
    "    child_1_tag = None\n",
    "    child_2_tag = None\n",
    "    child_3_tag = None\n",
    "    child_1_percent = 0\n",
    "    child_2_percent = 0\n",
    "    child_3_percent = 0\n",
    "    \n",
    "    # Calculate node area\n",
    "    node_width = node_data.get(\"width\", 0)\n",
    "    if not body_width or body_width == 0:\n",
    "        body_width = node_width\n",
    "    node_height = node_data.get(\"height\", 0)\n",
    "    node_area = node_width * node_height\n",
    "    \n",
    "    # Extract child information if available => (Each child tag and its percentage of the parent area)\n",
    "    if num_direct_children > 0:\n",
    "        # Child 1\n",
    "        if len(children) >= 1:\n",
    "            child_1_tag = children[0].get(\"tag\", \"\")\n",
    "            child_1_width = children[0].get(\"node\", {}).get(\"width\", 0)\n",
    "            child_1_height = children[0].get(\"node\", {}).get(\"height\", 0)\n",
    "            child_1_area = child_1_width * child_1_height\n",
    "            child_1_percent = (child_1_area / node_area) if node_area > 0 else 0\n",
    "        \n",
    "        # Child 2\n",
    "        if len(children) >= 2:\n",
    "            child_2_tag = children[1].get(\"tag\", \"\")\n",
    "            child_2_width = children[1].get(\"node\", {}).get(\"width\", 0)\n",
    "            child_2_height = children[1].get(\"node\", {}).get(\"height\", 0)\n",
    "            child_2_area = child_2_width * child_2_height\n",
    "            child_2_percent = (child_2_area / node_area) if node_area > 0 else 0\n",
    "        \n",
    "        # Child 3\n",
    "        if len(children) >= 3:\n",
    "            child_3_tag = children[2].get(\"tag\", \"\")\n",
    "            child_3_width = children[2].get(\"node\", {}).get(\"width\", 0)\n",
    "            child_3_height = children[2].get(\"node\", {}).get(\"height\", 0)\n",
    "            child_3_area = child_3_width * child_3_height\n",
    "            child_3_percent = (child_3_area / node_area) if node_area > 0 else 0\n",
    "    \n",
    "    # Calculate total descendants\n",
    "    num_children_to_end = count_all_descendants(node)\n",
    "    chars_count_to_end = count_chars_to_end(node)\n",
    "    bg_color = None\n",
    "    feature = {\n",
    "        \"tag\": tag,\n",
    "        \"type\": node_type,\n",
    "        \"x\": node_data.get(\"x\", 0),\n",
    "        \"y\": node_data.get(\"y\", 0),\n",
    "        \"width\": node_width/(body_width if body_width else 1),\n",
    "        \"height\": node_height/(parent_height if parent_height else node_height if node_height else 1),\n",
    "        \"characters\": text,\n",
    "        \"has_text\": int(bool(text)),\n",
    "        \"depth\": depth,\n",
    "        \"num_direct_children\": num_direct_children,\n",
    "        \"num_children_to_end\": num_children_to_end,  # Total descendants count\n",
    "        \"parent_tag\": parent_tag if parent_tag else \"\",\n",
    "        \"parent_tag_html\": parent_tag_html if parent_tag_html else \"\",\n",
    "        \"sibling_count\": sibling_count,\n",
    "        \"prev_sibling_html_tag\": prev_sibling_tag if prev_sibling_tag else \"\",\n",
    "        \"is_leaf\": is_leaf,\n",
    "        \"font_size\": node_data.get(\"fontSize\", 16),\n",
    "        \"has_font_size\": int(\"fontSize\" in node_data),\n",
    "        \"font_name\": node_data.get(\"fontName\", {}).get(\"style\", \"\") if node_data.get(\"fontName\") else \"normal\",\n",
    "        \"has_text_color\": 0, \"color_r\": 0, \"color_g\": 0, \"color_b\": 0,\n",
    "        \"has_background_color\": 0, \"background_r\": 0, \"background_g\": 0, \"background_b\": 0,\n",
    "        \"border_radius\": 0,\n",
    "        \"border_r\": 0, \"border_g\": 0, \"border_b\": 0,\n",
    "        \"has_border\": 0, \"border_opacity\": 0,\n",
    "        \"border_weight\": node_data.get(\"strokeWeight\", 0),\n",
    "        \"has_shadow\": 0, \"shadow_r\": 0, \"shadow_g\": 0, \"shadow_b\": 0,\n",
    "        \"shadow_radius\": 0, \n",
    "        \"text_length\": text_length,\n",
    "        \"chars_count_to_end\": chars_count_to_end,\n",
    "        \"word_count\": word_count,\n",
    "        \"contains_number\": int(contains_number),\n",
    "        \"contains_special_chars\": int(contains_special_chars),\n",
    "        \"aspect_ratio\": node_width / node_height if node_height > 0 else 0,\n",
    "        \"child_1_html_tag\": child_1_tag,\n",
    "        \"child_2_html_tag\": child_2_tag,\n",
    "        \"child_3_html_tag\": child_3_tag,\n",
    "        \"child_1_percentage_of_parent\": child_1_percent,\n",
    "        \"child_2_percentage_of_parent\": child_2_percent,\n",
    "        \"child_3_percentage_of_parent\": child_3_percent,\n",
    "        \"distinct_background\": 0,\n",
    "        \"center_of_weight_diff\": get_center_of_weight(node),\n",
    "    }\n",
    "    \n",
    "    # Extract fills (background and text color)\n",
    "    fills = node_data.get(\"fills\", [])\n",
    "    for fill in fills:\n",
    "        if fill.get(\"type\") == \"SOLID\" and \"color\" in fill:\n",
    "            r, g, b = (\n",
    "                int(fill[\"color\"].get(\"r\", 0) * 255),\n",
    "                int(fill[\"color\"].get(\"g\", 0) * 255),\n",
    "                int(fill[\"color\"].get(\"b\", 0) * 255),\n",
    "            )\n",
    "            feature[\"color_r\"], feature[\"color_g\"], feature[\"color_b\"] = r, g, b\n",
    "            feature[\"has_text_color\"] = 1\n",
    "            \n",
    "            feature[\"background_r\"], feature[\"background_g\"], feature[\"background_b\"] = r, g, b\n",
    "            feature[\"has_background_color\"] = 1 \n",
    "            a = min(float(fill[\"color\"].get(\"a\", 1)),float(fill.get(\"opacity\",1)))\n",
    "            \n",
    "            bg_color = (r*a, g*a, b*a)\n",
    "            check = \"NO\"\n",
    "            if parent_bg_color:\n",
    "                bg_difference = color_difference(bg_color, parent_bg_color)               \n",
    "                # If difference is significant (threshold of 0.2)\n",
    "                if bg_difference > 0.2:\n",
    "                    feature[\"distinct_background\"] = 1    \n",
    "            break\n",
    "    \n",
    "    # Also check backgrounds for background color (Special case for figma type Group)\n",
    "    backgrounds = node_data.get(\"backgrounds\", [])\n",
    "    for bg in backgrounds:\n",
    "        if bg.get(\"type\") == \"SOLID\" and \"color\" in bg:\n",
    "            r, g, b = (\n",
    "                int(bg[\"color\"].get(\"r\", 0) * 255),\n",
    "                int(bg[\"color\"].get(\"g\", 0) * 255),\n",
    "                int(bg[\"color\"].get(\"b\", 0) * 255),\n",
    "            )\n",
    "            feature[\"background_r\"], feature[\"background_g\"], feature[\"background_b\"] = r, g, b\n",
    "            feature[\"has_background_color\"] = 1 \n",
    "            break\n",
    "    \n",
    "    # Extract strokes (borders)\n",
    "    strokes = node_data.get(\"strokes\", [])\n",
    "    if strokes:\n",
    "        stroke = strokes[0]\n",
    "        feature[\"has_border\"] = 1\n",
    "        if \"color\" in stroke:\n",
    "            feature[\"border_r\"], feature[\"border_g\"], feature[\"border_b\"] = (\n",
    "                int(stroke[\"color\"].get(\"r\", 0) * 255),\n",
    "                int(stroke[\"color\"].get(\"g\", 0) * 255),\n",
    "                int(stroke[\"color\"].get(\"b\", 0) * 255),\n",
    "            )\n",
    "        feature[\"border_opacity\"] = stroke.get(\"opacity\", 0)\n",
    "    \n",
    "    # Extract border radius\n",
    "    br_top_left = node_data.get(\"topLeftRadius\", 0)\n",
    "    br_top_right = node_data.get(\"topRightRadius\", 0)\n",
    "    br_bottom_left = node_data.get(\"bottomLeftRadius\", 0)\n",
    "    br_bottom_right = node_data.get(\"bottomRightRadius\", 0)\n",
    "    \n",
    "    if any([br_top_left, br_top_right, br_bottom_left, br_bottom_right]):\n",
    "        feature[\"border_radius\"] = (br_top_left + br_top_right + br_bottom_left + br_bottom_right) / 4\n",
    "        if feature[\"border_radius\"] >= 50:\n",
    "            feature[\"border_radius\"] = 0\n",
    "    \n",
    "    # Extract shadow\n",
    "    effects = node_data.get(\"effects\", [])\n",
    "    for effect in effects:\n",
    "        if effect.get(\"type\") == \"DROP_SHADOW\":\n",
    "            feature[\"has_shadow\"] = 1\n",
    "            if \"color\" in effect:\n",
    "                feature[\"shadow_r\"], feature[\"shadow_g\"], feature[\"shadow_b\"] = (\n",
    "                    int(effect[\"color\"].get(\"r\", 0) * 255),\n",
    "                    int(effect[\"color\"].get(\"g\", 0) * 255),\n",
    "                    int(effect[\"color\"].get(\"b\", 0) * 255),\n",
    "                )\n",
    "            feature[\"shadow_radius\"] = effect.get(\"radius\", 0)\n",
    "            break  \n",
    "    \n",
    "    # Get semantic features for the current node\n",
    "    semantic_features = extract_semantic_features(node, text_nodes)\n",
    "    \n",
    "    # Calculate nearest text node distance\n",
    "    nearest_text_distance = semantic_features.get('nearest_text_semantic_distance',0)\n",
    "    nearest_text_semantic = semantic_features.get('nearest_text_semantic_vector',[0]*384)\n",
    "    \n",
    "    # Add nearest text node distance to the feature vector\n",
    "    feature[\"nearest_text_node_dist\"] = (nearest_text_distance) / (math.sqrt((node_width)* (node_height)) if math.sqrt((node_width)*(node_height)) else 1)\n",
    "    feature[\"nearest_text_semantic\"] = nearest_text_semantic\n",
    "    features.append(feature)\n",
    "    \n",
    "    # Process children with previous sibling information\n",
    "    prev_sib_tag = None\n",
    "    for child in children:\n",
    "        features.extend(extract_features(\n",
    "            child, \n",
    "            depth=depth+1, \n",
    "            parent_tag=node_type, \n",
    "            sibling_count=len(children)-1, \n",
    "            parent_tag_html=tag,\n",
    "            prev_sibling_tag=prev_sib_tag,\n",
    "            parent_height= node_height,\n",
    "            parent_bg_color=bg_color if feature[\"has_background_color\"] else parent_bg_color,\n",
    "            text_nodes=text_nodes\n",
    "        ))\n",
    "        prev_sib_tag = child.get(\"tag\", \"\")\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Folder containing JSON files\n",
    "data_folder = \"../../Data/new_json_data6\"\n",
    "output_csv_file = \"../Output/semantic_figma_dataset.csv\"\n",
    "\n",
    "# If the output CSV exists, remove it so we start fresh\n",
    "if os.path.exists(output_csv_file):\n",
    "    os.remove(output_csv_file)\n",
    "\n",
    "# Flag to write header only for the first batch\n",
    "first_batch = True\n",
    "\n",
    "# Iterate over all JSON files in the data folder\n",
    "for filename in os.listdir(data_folder):\n",
    "    if filename.endswith(\".json\"):\n",
    "        file_path = os.path.join(data_folder, filename)\n",
    "        print(f\"Processing {file_path}...\")\n",
    "        \n",
    "        with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "            data = json.load(file)\n",
    "        \n",
    "        # Extract features using the recursive function starting at the root\n",
    "        features_list = extract_features(data, depth=0, parent_tag=None, sibling_count=0, parent_tag_html=None, parent_height= 0, parent_bg_color=None)\n",
    "        if not features_list:\n",
    "            continue  # Skip if no features extracted\n",
    "        \n",
    "        df = pd.DataFrame(features_list)\n",
    "\n",
    "        columns_to_drop = [\n",
    "                \"x\", \"y\", \"characters\", \"font_size\", \"font_name\", \"color_r\", \"color_g\", \"color_b\",\n",
    "                \"background_r\", \"background_g\", \"background_b\", \"border_r\", \"border_g\", \"border_b\",\n",
    "                \"border_opacity\", \"border_weight\", \"shadow_r\", \"shadow_g\", \"shadow_b\", \"shadow_radius\",\n",
    "                \"word_count\", \"contains_special_chars\", \"contains_number\", \"has_shadow\", \"has_border\",\n",
    "                \"has_text_color\", \"has_text\", \"depth\", \"has_font_size\", \"parent_tag\", \"is_leaf\",\n",
    "                \"child_3_html_tag\", \"child_3_percentage_of_parent\", \"num_direct_children\", \"text_length\",\n",
    "                \"chars_count_to_end\", \"num_children_to_end\"\n",
    "            ]\n",
    "        df = df.drop(columns=columns_to_drop, errors='ignore')\n",
    "\n",
    "        # Append to CSV with header for the first batch only\n",
    "        df.to_csv(output_csv_file, mode='a', header=first_batch, index=False)\n",
    "        first_batch = False\n",
    "\n",
    "print(f\"Extracted features from all JSON files have been saved to {output_csv_file}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
