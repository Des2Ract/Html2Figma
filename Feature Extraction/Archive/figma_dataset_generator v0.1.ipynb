{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def color_difference(color1, color2):\n",
    "    if not all([color1, color2]):\n",
    "        return 0\n",
    "    \n",
    "    r1, g1, b1 = color1\n",
    "    r2, g2, b2 = color2\n",
    "    \n",
    "    distance = math.sqrt((r2-r1)**2 + (g2-g1)**2 + (b2-b1)**2)\n",
    "    \n",
    "    max_distance = math.sqrt(3 * 255**2)\n",
    "    normalized_distance = distance / max_distance\n",
    "    \n",
    "    return normalized_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(node, depth=0, parent_tag=None, sibling_count=0, parent_tag_html=None, \n",
    "                    prev_sibling_tag=None, parent_prev_sibling_tag=None, parent_bg_color=None):\n",
    "    features = []\n",
    "    text_nodes = []\n",
    "    svg_image_nodes = []\n",
    "    \n",
    "    tag = node.get(\"tag\", \"\")\n",
    "    node_data = node.get(\"node\", {})\n",
    "    node_type = str(node_data.get(\"type\", \"\"))\n",
    "\n",
    "    text = node_data.get(\"characters\", \"\")\n",
    "    text_length = len(text)\n",
    "    word_count = len(text.split()) if text else 0\n",
    "    contains_number = any(ch.isdigit() for ch in text)\n",
    "    contains_special_chars = any(not ch.isalnum() and not ch.isspace() for ch in text)\n",
    "    \n",
    "    children = node.get(\"children\", [])\n",
    "    num_children = len(children)\n",
    "    is_leaf = 1 if num_children == 0 else 0\n",
    "    \n",
    "    total_descendants = num_children\n",
    "    \n",
    "    total_text_nodes = 1 if node_type == \"TEXT\" else 0\n",
    "    \n",
    "    total_text_length = text_length if node_type == \"TEXT\" else 0\n",
    "    \n",
    "    # Use BFS to count all descendants and text nodes\n",
    "    queue = list(children)\n",
    "    while queue:\n",
    "        child = queue.pop(0)\n",
    "        child_children = child.get(\"children\", [])\n",
    "        child_type = str(child.get(\"node\", {}).get(\"type\", \"\"))\n",
    "        child_text = child.get(\"node\", {}).get(\"characters\", \"\")\n",
    "        \n",
    "        total_descendants += len(child_children)\n",
    "        \n",
    "        if child_type == \"TEXT\":\n",
    "            total_text_nodes += 1\n",
    "            total_text_length += len(child_text)\n",
    "            \n",
    "        queue.extend(child_children)\n",
    "    \n",
    "    bg_color = None\n",
    "    has_distinct_bg = 0\n",
    "    bg_difference = 0\n",
    "\n",
    "    feature = {\n",
    "        \"tag\": tag,\n",
    "        \"type\": node_type,\n",
    "        \"x\": node_data.get(\"x\", 0),\n",
    "        \"y\": node_data.get(\"y\", 0),\n",
    "        \"width\": node_data.get(\"width\", 0),\n",
    "        \"height\": node_data.get(\"height\", 0),\n",
    "        \"characters\": text,\n",
    "        \"has_text\": int(bool(text)),\n",
    "        \"depth\": depth,\n",
    "        \"num_children\": num_children,\n",
    "        \"total_descendants\": total_descendants,\n",
    "        \"total_text_nodes\": total_text_nodes,  # Count of all text nodes\n",
    "        \"total_text_length\": total_text_length,  # New feature: sum of all text lengths\n",
    "        \"parent_tag\": parent_tag if parent_tag else \"\",\n",
    "        \"parent_tag_html\": parent_tag_html if parent_tag_html else \"\",\n",
    "        \"prev_sibling_tag\": prev_sibling_tag if prev_sibling_tag else \"\",\n",
    "        \"parent_prev_sibling_tag\": parent_prev_sibling_tag if parent_prev_sibling_tag else \"\",\n",
    "        \"sibling_count\": sibling_count,\n",
    "        \"is_leaf\": is_leaf,\n",
    "        \"font_size\": node_data.get(\"fontSize\", 16),\n",
    "        \"has_font_size\": int(\"fontSize\" in node_data),\n",
    "        \"font_name\": node_data.get(\"fontName\", {}).get(\"style\", \"\") if node_data.get(\"fontName\") else \"normal\",\n",
    "        \"has_text_color\": 0, \"color_r\": 0, \"color_g\": 0, \"color_b\": 0,\n",
    "        \"has_background_color\": 0, \"background_r\": 0, \"background_g\": 0, \"background_b\": 0,\n",
    "        \"distinct_background\": 0,  \n",
    "        \"border_radius\": 0,\n",
    "        \"border_r\": 0, \"border_g\": 0, \"border_b\": 0,\n",
    "        \"has_border\": 0, \"border_opacity\": 0,\n",
    "        \"border_weight\": node_data.get(\"strokeWeight\", 0),\n",
    "        \"has_shadow\": 0, \"shadow_r\": 0, \"shadow_g\": 0, \"shadow_b\": 0,\n",
    "        \"shadow_radius\": 0, \n",
    "        \"text_length\": text_length,\n",
    "        \"word_count\": word_count,\n",
    "        \"contains_number\": int(contains_number),\n",
    "        \"contains_special_chars\": int(contains_special_chars),\n",
    "    }\n",
    "    \n",
    "    fills = node_data.get(\"fills\", [])\n",
    "    for fill in fills:\n",
    "        if fill.get(\"type\") == \"SOLID\" and \"color\" in fill:\n",
    "            r, g, b = (\n",
    "                int(fill[\"color\"].get(\"r\", 0) * 255),\n",
    "                int(fill[\"color\"].get(\"g\", 0) * 255),\n",
    "                int(fill[\"color\"].get(\"b\", 0) * 255),\n",
    "            )\n",
    "            feature[\"color_r\"], feature[\"color_g\"], feature[\"color_b\"] = r, g, b\n",
    "            feature[\"has_text_color\"] = 1  \n",
    "            \n",
    "            feature[\"background_r\"], feature[\"background_g\"], feature[\"background_b\"] = r, g, b\n",
    "            feature[\"has_background_color\"] = 1 \n",
    "    \n",
    "            bg_color = (r, g, b)\n",
    "            \n",
    "            if parent_bg_color:\n",
    "                bg_difference = color_difference(bg_color, parent_bg_color)\n",
    "                \n",
    "                \n",
    "                if bg_difference > 0.3:\n",
    "                    feature[\"distinct_background\"] = 1\n",
    "            else:   \n",
    "                bg_difference = color_difference(bg_color, (125, 125, 125))\n",
    "\n",
    "                if bg_difference > 0.3:\n",
    "                    feature[\"distinct_background\"] = 1\n",
    "\n",
    "\n",
    "            break  \n",
    "    \n",
    "    # Extract strokes (borders)\n",
    "    strokes = node_data.get(\"strokes\", [])\n",
    "    if strokes:\n",
    "        stroke = strokes[0]\n",
    "        feature[\"has_border\"] = 1\n",
    "        if \"color\" in stroke:\n",
    "            feature[\"border_r\"], feature[\"border_g\"], feature[\"border_b\"] = (\n",
    "                int(stroke[\"color\"].get(\"r\", 0) * 255),\n",
    "                int(stroke[\"color\"].get(\"g\", 0) * 255),\n",
    "                int(stroke[\"color\"].get(\"b\", 0) * 255),\n",
    "            )\n",
    "        feature[\"border_opacity\"] = stroke.get(\"opacity\", 0)\n",
    "    \n",
    "    # Extract border radius\n",
    "    br_top_left = node_data.get(\"topLeftRadius\", 0)\n",
    "    br_top_right = node_data.get(\"topRightRadius\", 0)\n",
    "    br_bottom_left = node_data.get(\"bottomLeftRadius\", 0)\n",
    "    br_bottom_right = node_data.get(\"bottomRightRadius\", 0)\n",
    "    \n",
    "    if any([br_top_left, br_top_right, br_bottom_left, br_bottom_right]):\n",
    "        feature[\"border_radius\"] = (br_top_left + br_top_right + br_bottom_left + br_bottom_right) / 4\n",
    "    \n",
    "    # Extract shadow\n",
    "    effects = node_data.get(\"effects\", [])\n",
    "    for effect in effects:\n",
    "        if effect.get(\"type\") == \"DROP_SHADOW\":\n",
    "            feature[\"has_shadow\"] = 1\n",
    "            if \"color\" in effect:\n",
    "                feature[\"shadow_r\"], feature[\"shadow_g\"], feature[\"shadow_b\"] = (\n",
    "                    int(effect[\"color\"].get(\"r\", 0) * 255),\n",
    "                    int(effect[\"color\"].get(\"g\", 0) * 255),\n",
    "                    int(effect[\"color\"].get(\"b\", 0) * 255),\n",
    "                )\n",
    "            feature[\"shadow_radius\"] = effect.get(\"radius\", 0)\n",
    "            break  \n",
    "    \n",
    "    features.append(feature)\n",
    "    \n",
    "    # Add to text_nodes if this is a TEXT node\n",
    "    if node_type == \"TEXT\":\n",
    "        text_nodes.append({\n",
    "            \"characters\": text,\n",
    "            \"x\": node_data.get(\"x\", 0),\n",
    "            \"y\": node_data.get(\"y\", 0),\n",
    "            \"width\": node_data.get(\"width\", 0),\n",
    "            \"height\": node_data.get(\"height\", 0),\n",
    "        })\n",
    "    \n",
    "    # Add to svg_image_nodes if this is an SVG or IMAGE node\n",
    "    if tag in [\"SVG\", \"IMAGE\", \"PICTURE\"]:\n",
    "        svg_image_nodes.append({\n",
    "            \"tag\": tag,\n",
    "            \"type\": node_type,\n",
    "            \"x\": node_data.get(\"x\", 0),\n",
    "            \"y\": node_data.get(\"y\", 0),\n",
    "            \"width\": node_data.get(\"width\", 0),\n",
    "            \"height\": node_data.get(\"height\", 0),\n",
    "            \"depth\": depth,\n",
    "            \"parent_tag\": parent_tag if parent_tag else \"\",\n",
    "            \"parent_tag_html\": parent_tag_html if parent_tag_html else \"\"\n",
    "        })\n",
    "    \n",
    "    # Process children with updated sibling information\n",
    "    prev_child_tag = None\n",
    "    for child in children:\n",
    "        child_features, child_text_nodes, child_svg_image_nodes = extract_features(\n",
    "            child, \n",
    "            depth=depth+1, \n",
    "            parent_tag=node_type, \n",
    "            sibling_count=len(children)-1, \n",
    "            parent_tag_html=tag,\n",
    "            prev_sibling_tag=prev_child_tag,\n",
    "            parent_prev_sibling_tag=prev_sibling_tag,\n",
    "            parent_bg_color=bg_color  # Pass the current node's background color to its children\n",
    "        )\n",
    "        features.extend(child_features)\n",
    "        text_nodes.extend(child_text_nodes)\n",
    "        svg_image_nodes.extend(child_svg_image_nodes)\n",
    "        \n",
    "        # Update the previous sibling tag for the next child\n",
    "        prev_child_tag = child.get(\"tag\", \"\")\n",
    "    \n",
    "    return features, text_nodes, svg_image_nodes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ../json_data\\figmaTree_1.json...\n",
      "Processing ../json_data\\figmaTree_10.json...\n",
      "Processing ../json_data\\figmaTree_100.json...\n",
      "Processing ../json_data\\figmaTree_101.json...\n",
      "Processing ../json_data\\figmaTree_102.json...\n",
      "Processing ../json_data\\figmaTree_11.json...\n",
      "Processing ../json_data\\figmaTree_12.json...\n",
      "Processing ../json_data\\figmaTree_13.json...\n",
      "Processing ../json_data\\figmaTree_14.json...\n",
      "Processing ../json_data\\figmaTree_16.json...\n",
      "Processing ../json_data\\figmaTree_18.json...\n",
      "Processing ../json_data\\figmaTree_19.json...\n",
      "Processing ../json_data\\figmaTree_2.json...\n",
      "Processing ../json_data\\figmaTree_20.json...\n",
      "Processing ../json_data\\figmaTree_21.json...\n",
      "Processing ../json_data\\figmaTree_22.json...\n",
      "Processing ../json_data\\figmaTree_23.json...\n",
      "Processing ../json_data\\figmaTree_24.json...\n",
      "Processing ../json_data\\figmaTree_25.json...\n",
      "Processing ../json_data\\figmaTree_26.json...\n",
      "Processing ../json_data\\figmaTree_27.json...\n",
      "Processing ../json_data\\figmaTree_28.json...\n",
      "Processing ../json_data\\figmaTree_29.json...\n",
      "Processing ../json_data\\figmaTree_3.json...\n",
      "Processing ../json_data\\figmaTree_30.json...\n",
      "Processing ../json_data\\figmaTree_31.json...\n",
      "Processing ../json_data\\figmaTree_32.json...\n",
      "Processing ../json_data\\figmaTree_33.json...\n",
      "Processing ../json_data\\figmaTree_34.json...\n",
      "Processing ../json_data\\figmaTree_35.json...\n",
      "Processing ../json_data\\figmaTree_36.json...\n",
      "Processing ../json_data\\figmaTree_37.json...\n",
      "Processing ../json_data\\figmaTree_38.json...\n",
      "Processing ../json_data\\figmaTree_39.json...\n",
      "Processing ../json_data\\figmaTree_4.json...\n",
      "Processing ../json_data\\figmaTree_40.json...\n",
      "Processing ../json_data\\figmaTree_41.json...\n",
      "Processing ../json_data\\figmaTree_42.json...\n",
      "Processing ../json_data\\figmaTree_43.json...\n",
      "Processing ../json_data\\figmaTree_44.json...\n",
      "Processing ../json_data\\figmaTree_45.json...\n",
      "Processing ../json_data\\figmaTree_46.json...\n",
      "Processing ../json_data\\figmaTree_47.json...\n",
      "Processing ../json_data\\figmaTree_48.json...\n",
      "Processing ../json_data\\figmaTree_49.json...\n",
      "Processing ../json_data\\figmaTree_50.json...\n",
      "Processing ../json_data\\figmaTree_51.json...\n",
      "Processing ../json_data\\figmaTree_52.json...\n",
      "Processing ../json_data\\figmaTree_53.json...\n",
      "Processing ../json_data\\figmaTree_54.json...\n",
      "Processing ../json_data\\figmaTree_55.json...\n",
      "Processing ../json_data\\figmaTree_56.json...\n",
      "Processing ../json_data\\figmaTree_57.json...\n",
      "Processing ../json_data\\figmaTree_58.json...\n",
      "Processing ../json_data\\figmaTree_59.json...\n",
      "Processing ../json_data\\figmaTree_6.json...\n",
      "Processing ../json_data\\figmaTree_60.json...\n",
      "Processing ../json_data\\figmaTree_61.json...\n",
      "Processing ../json_data\\figmaTree_62.json...\n",
      "Processing ../json_data\\figmaTree_63.json...\n",
      "Processing ../json_data\\figmaTree_64.json...\n",
      "Processing ../json_data\\figmaTree_65.json...\n",
      "Processing ../json_data\\figmaTree_66.json...\n",
      "Processing ../json_data\\figmaTree_67.json...\n",
      "Processing ../json_data\\figmaTree_68.json...\n",
      "Processing ../json_data\\figmaTree_69.json...\n",
      "Processing ../json_data\\figmaTree_7.json...\n",
      "Processing ../json_data\\figmaTree_70.json...\n",
      "Processing ../json_data\\figmaTree_71.json...\n",
      "Processing ../json_data\\figmaTree_72.json...\n",
      "Processing ../json_data\\figmaTree_73.json...\n",
      "Processing ../json_data\\figmaTree_74.json...\n",
      "Processing ../json_data\\figmaTree_75.json...\n",
      "Processing ../json_data\\figmaTree_76.json...\n",
      "Processing ../json_data\\figmaTree_78.json...\n",
      "Processing ../json_data\\figmaTree_79.json...\n",
      "Processing ../json_data\\figmaTree_8.json...\n",
      "Processing ../json_data\\figmaTree_80.json...\n",
      "Processing ../json_data\\figmaTree_81.json...\n",
      "Processing ../json_data\\figmaTree_82.json...\n",
      "Processing ../json_data\\figmaTree_83.json...\n",
      "Processing ../json_data\\figmaTree_84.json...\n",
      "Processing ../json_data\\figmaTree_85.json...\n",
      "Processing ../json_data\\figmaTree_86.json...\n",
      "Processing ../json_data\\figmaTree_87.json...\n",
      "Processing ../json_data\\figmaTree_88.json...\n",
      "Processing ../json_data\\figmaTree_89.json...\n",
      "Processing ../json_data\\figmaTree_9.json...\n",
      "Processing ../json_data\\figmaTree_90.json...\n",
      "Processing ../json_data\\figmaTree_91.json...\n",
      "Processing ../json_data\\figmaTree_92.json...\n",
      "Processing ../json_data\\figmaTree_93.json...\n",
      "Processing ../json_data\\figmaTree_94.json...\n",
      "Processing ../json_data\\figmaTree_95.json...\n",
      "Processing ../json_data\\figmaTree_96.json...\n",
      "Processing ../json_data\\figmaTree_97.json...\n",
      "Processing ../json_data\\figmaTree_98.json...\n",
      "Processing ../json_data\\figmaTree_99.json...\n",
      "Extracted features from all JSON files have been saved to figma_dataset.csv\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Folder containing JSON files\n",
    "data_folder = \"../json_data\"\n",
    "output_csv_file = \"figma_dataset.csv\"\n",
    "\n",
    "# normalize on body features\n",
    "normalize_columns = [\n",
    "    \"area\",\n",
    "    \"word_count\",\n",
    "    # \"text_length\",\n",
    "    \"font_size\",\n",
    "    # \"sibling_count\",\n",
    "    # \"num_children\",\n",
    "    \"height\",\n",
    "    \"width\",\n",
    "    \"depth\"\n",
    "]\n",
    "\n",
    "# Add the necessary import if not already present\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import euclidean\n",
    "\n",
    "# If the output CSV exists, remove it so we start fresh\n",
    "if os.path.exists(output_csv_file):\n",
    "    os.remove(output_csv_file)\n",
    "\n",
    "# Flag to write header only for the first batch\n",
    "first_batch = True\n",
    "\n",
    "# Define a function to calculate Euclidean distance between two nodes\n",
    "def calculate_distance(node1, node2):\n",
    "    # Calculate centers of nodes\n",
    "    node1_center_x = node1['x'] + node1['width'] / 2\n",
    "    node1_center_y = node1['y'] + node1['height'] / 2\n",
    "    node2_center_x = node2['x'] + node2['width'] / 2\n",
    "    node2_center_y = node2['y'] + node2['height'] / 2\n",
    "    \n",
    "    # Calculate Euclidean distance between centers\n",
    "    if any(np.isnan([node1_center_x, node1_center_y, node2_center_x, node2_center_y])) or any(np.isinf([node1_center_x, node1_center_y, node2_center_x, node2_center_y])):\n",
    "        return float('inf')\n",
    "    return euclidean((node1_center_x, node1_center_y), (node2_center_x, node2_center_y))\n",
    "\n",
    "# Iterate over all JSON files in the data folder\n",
    "for filename in os.listdir(data_folder):\n",
    "    if filename.endswith(\".json\"):\n",
    "        file_path = os.path.join(data_folder, filename)\n",
    "        print(f\"Processing {file_path}...\")\n",
    "        \n",
    "        with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "            data = json.load(file)\n",
    "        \n",
    "        # Extract features using the recursive function starting at the root\n",
    "        features_list, child_text_nodes, child_svg_image_nodes = extract_features(data, depth=0, parent_tag=None, sibling_count=0, parent_tag_html=None)\n",
    "        if not features_list:\n",
    "            continue  # Skip if no features extracted\n",
    "        \n",
    "        df = pd.DataFrame(features_list)\n",
    "        \n",
    "        # Normalize positions per JSON file to avoid cross-file influence\n",
    "        min_x = df['x'].min() if df['x'].notnull().any() else 0\n",
    "        min_y = df['y'].min() if df['y'].notnull().any() else 0\n",
    "        df['x_normalized'] = df['x'] - min_x\n",
    "        df['y_normalized'] = df['y'] - min_y\n",
    "        \n",
    "        df['x_center'] = df['x'] + df['width'] / 2\n",
    "        df['y_center'] = df['y'] + df['height'] / 2\n",
    "        \n",
    "        # Attempt to compute total dimensions using a BODY tag if available\n",
    "        body_node = df[df['tag'] == 'BODY']\n",
    "        if not body_node.empty:\n",
    "            total_width = body_node.iloc[0]['width']\n",
    "            total_height = body_node.iloc[0]['height']\n",
    "        else:\n",
    "            total_width = (df['x'] + df['width']).max()\n",
    "            total_height = (df['y'] + df['height']).max()\n",
    "        \n",
    "        # Avoid division by zero\n",
    "        if total_width and total_height:\n",
    "            df['x_quarter'] = df['x_center'] / total_width\n",
    "            df['y_quarter'] = df['y_center'] / total_height\n",
    "        else:\n",
    "            df['x_quarter'] = None\n",
    "            df['y_quarter'] = None\n",
    "        \n",
    "        df['aspect_ratio'] = df.apply(\n",
    "            lambda row: row['width'] / row['height'] if row['height'] and row['height'] != 0 else None, axis=1\n",
    "        )\n",
    "        df['area'] = df['width'] * df['height']\n",
    "        if total_width:\n",
    "            df['normalized_width'] = df['width'] / total_width\n",
    "        else:\n",
    "            df['normalized_width'] = None\n",
    "        if total_height:\n",
    "            df['normalized_height'] = df['height'] / total_height\n",
    "        else:\n",
    "            df['normalized_height'] = None\n",
    "\n",
    "        # 1. Add feature: distance to nearest text node and its characters\n",
    "        df['nearest_text_distance'] = None\n",
    "        df['nearest_text_content'] = None\n",
    "        \n",
    "        # Define threshold distance for considering an image \"nearby\"\n",
    "        threshold_distance = total_width * 0.2  # 20% of total width as threshold\n",
    "        \n",
    "        # 2. Add feature: size of nearest image/svg and distance to it\n",
    "        df['nearest_image_size'] = None\n",
    "        df['nearest_image_distance'] = None\n",
    "        \n",
    "        # Process each node to find nearest text and image\n",
    "        for idx, node in df.iterrows():\n",
    "            # Get node center\n",
    "            node_center_x = node['x_center']\n",
    "            node_center_y = node['y_center']\n",
    "            node_data = {\n",
    "                'x': node['x'],\n",
    "                'y': node['y'],\n",
    "                'width': node['width'],\n",
    "                'height': node['height']\n",
    "            }\n",
    "            \n",
    "            # 1. Find nearest text node\n",
    "            min_text_distance = float('inf')\n",
    "            nearest_text_content = \"\"\n",
    "            \n",
    "            for text_node in child_text_nodes:\n",
    "                distance = calculate_distance(node_data, text_node)\n",
    "                \n",
    "                if distance < min_text_distance:\n",
    "                    min_text_distance = distance\n",
    "                    nearest_text_content = text_node.get('characters', '')\n",
    "            \n",
    "            if min_text_distance != float('inf'):\n",
    "                df.at[idx, 'nearest_text_distance'] = min_text_distance\n",
    "                df.at[idx, 'nearest_text_content'] = nearest_text_content\n",
    "            else:\n",
    "                df.at[idx, 'nearest_text_distance'] = -1  # No text nodes found\n",
    "                df.at[idx, 'nearest_text_content'] = \"\"\n",
    "            \n",
    "            # 2. Find nearest image/svg within threshold\n",
    "            min_image_distance = float('inf')\n",
    "            nearest_image_size = 0\n",
    "            \n",
    "            for image_node in child_svg_image_nodes:\n",
    "                distance = calculate_distance(node_data, image_node)\n",
    "                \n",
    "                if distance < min_image_distance:\n",
    "                    min_image_distance = distance\n",
    "                    # Calculate image size (area)\n",
    "                    image_size = image_node.get('width', 0) * image_node.get('height', 0)\n",
    "                    nearest_image_size = image_size\n",
    "            \n",
    "            if min_image_distance != float('inf'):\n",
    "                df.at[idx, 'nearest_image_distance'] = min_image_distance\n",
    "                \n",
    "                # Store image size if within threshold, otherwise 0\n",
    "                if min_image_distance <= threshold_distance:\n",
    "                    df.at[idx, 'nearest_image_size'] = nearest_image_size\n",
    "                else:\n",
    "                    df.at[idx, 'nearest_image_size'] = 0\n",
    "            else:\n",
    "                df.at[idx, 'nearest_image_distance'] = -1  # No image nodes found\n",
    "                df.at[idx, 'nearest_image_size'] = 0\n",
    "\n",
    "        # Normalize the new features\n",
    "        if 'nearest_text_distance' in normalize_columns:\n",
    "            max_text_dist = df['nearest_text_distance'].max()\n",
    "            if max_text_dist > 0:\n",
    "                df['nearest_text_distance'] = df['nearest_text_distance'] / max_text_dist\n",
    "        \n",
    "        if 'nearest_image_size' in normalize_columns:\n",
    "            max_image_size = df['nearest_image_size'].max()\n",
    "            if max_image_size > 0:\n",
    "                df['nearest_image_size'] = df['nearest_image_size'] / max_image_size\n",
    "        \n",
    "        if 'nearest_image_distance' in normalize_columns:\n",
    "            max_image_dist = df['nearest_image_distance'].max()\n",
    "            if max_image_dist > 0:\n",
    "                df['nearest_image_distance'] = df['nearest_image_distance'] / max_image_dist\n",
    "\n",
    "        # Compute min and max for each column\n",
    "        min_max_values = {col: (df[col].min(), df[col].max()) for col in normalize_columns}\n",
    "\n",
    "        # Apply Min-Max normalization (scaling between 0 and 1)\n",
    "        for col in normalize_columns:\n",
    "            min_val, max_val = min_max_values[col]\n",
    "            if max_val > min_val and max_val != 0:  # Avoid division by zero\n",
    "                df[col] = df[col] / max_val\n",
    "            else:\n",
    "                df[col] = 0  # If min and max are the same, set to 0\n",
    "\n",
    "        # Remove columns that aren't needed\n",
    "        columns_to_drop = [\n",
    "            'x', 'y', 'x_normalized', 'y_normalized', 'x_center', 'y_center', \n",
    "            'characters', 'font_size', 'font_name', 'color_r', 'color_g', 'color_b',\n",
    "            'background_r', 'background_g', 'background_b', 'border_radius',\n",
    "            'border_r', 'border_g', 'border_b', 'border_opacity', 'border_weight',\n",
    "            'shadow_r', 'shadow_g', 'shadow_b', 'shadow_radius', 'word_count',\n",
    "            'normalized_width', 'normalized_height', 'contains_special_chars',\n",
    "            'contains_number', 'has_shadow', 'has_border', 'has_text_color',\n",
    "            'height', 'has_text', 'x_quarter', 'y_quarter', 'area', 'has_font_size'\n",
    "        ]\n",
    "        \n",
    "        # Safely drop columns that exist\n",
    "        for col in columns_to_drop:\n",
    "            if col in df.columns:\n",
    "                df = df.drop(columns=[col])\n",
    "        \n",
    "        # Write to CSV\n",
    "        df.to_csv(output_csv_file, mode='a', header=first_batch, index=False)\n",
    "        first_batch = False\n",
    "\n",
    "print(f\"Extracted features from all JSON files have been saved to {output_csv_file}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
