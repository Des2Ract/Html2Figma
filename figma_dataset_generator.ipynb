{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(node, depth=0, parent_tag=None, sibling_count=0):\n",
    "    features = []\n",
    "    \n",
    "    tag = node.get(\"tag\", \"\")\n",
    "    node_data = node.get(\"node\", {})\n",
    "    node_type = str(node_data.get(\"type\", \"\"))\n",
    "\n",
    "    text = node_data.get(\"characters\", \"\")\n",
    "    text_length = len(text)\n",
    "    word_count = len(text.split()) if text else 0\n",
    "    contains_number = any(ch.isdigit() for ch in text)\n",
    "    contains_special_chars = any(not ch.isalnum() and not ch.isspace() for ch in text)\n",
    "    \n",
    "    children = node.get(\"children\", [])\n",
    "    num_children = len(children)\n",
    "    is_leaf = 1 if num_children == 0 else 0\n",
    "    \n",
    "    feature = {\n",
    "        \"tag\": tag,\n",
    "        \"type\": node_type,\n",
    "        \"x\": node_data.get(\"x\", 0),\n",
    "        \"y\": node_data.get(\"y\", 0),\n",
    "        \"width\": node_data.get(\"width\", 0),\n",
    "        \"height\": node_data.get(\"height\", 0),\n",
    "        \"characters\": text,\n",
    "        \"has_text\": int(bool(text)),\n",
    "        \"depth\": depth,\n",
    "        \"num_children\": num_children,\n",
    "        \"parent_tag\": parent_tag if parent_tag else \"\",\n",
    "        \"sibling_count\": sibling_count,\n",
    "        \"is_leaf\": is_leaf,\n",
    "        \"font_size\": node_data.get(\"fontSize\", 16),\n",
    "        \"has_font_size\": int(\"fontSize\" in node_data),\n",
    "        \"font_name\": node_data.get(\"fontName\", {}).get(\"style\", \"\") if node_data.get(\"fontName\") else \"normal\",\n",
    "        \"has_text_color\": 0, \"color_r\": 0, \"color_g\": 0, \"color_b\": 0,\n",
    "        \"has_background_color\": 0, \"background_r\": 0, \"background_g\": 0, \"background_b\": 0,\n",
    "        \"border_radius\": 0,\n",
    "        \"border_r\": 0, \"border_g\": 0, \"border_b\": 0,\n",
    "        \"has_border\": 0, \"border_opacity\": 0,\n",
    "        \"border_weight\": node_data.get(\"strokeWeight\", 0),\n",
    "        \"has_shadow\": 0, \"shadow_r\": 0, \"shadow_g\": 0, \"shadow_b\": 0,\n",
    "        \"shadow_radius\": 0, \n",
    "        \"text_length\": text_length,\n",
    "        \"word_count\": word_count,\n",
    "        \"contains_number\": int(contains_number),\n",
    "        \"contains_special_chars\": int(contains_special_chars),\n",
    "    }\n",
    "    \n",
    "    # Extract fills (background and text color)\n",
    "    fills = node_data.get(\"fills\", [])\n",
    "    for fill in fills:\n",
    "        if fill.get(\"type\") == \"SOLID\" and \"color\" in fill:\n",
    "            r, g, b = (\n",
    "                int(fill[\"color\"].get(\"r\", 0) * 255),\n",
    "                int(fill[\"color\"].get(\"g\", 0) * 255),\n",
    "                int(fill[\"color\"].get(\"b\", 0) * 255),\n",
    "            )\n",
    "            feature[\"color_r\"], feature[\"color_g\"], feature[\"color_b\"] = r, g, b\n",
    "            feature[\"has_text_color\"] = 1  # Flag indicating explicit text color is set\n",
    "            \n",
    "            feature[\"background_r\"], feature[\"background_g\"], feature[\"background_b\"] = r, g, b\n",
    "            feature[\"has_background_color\"] = 1  # Flag for explicit background color\n",
    "            break  \n",
    "    \n",
    "    # Extract strokes (borders)\n",
    "    strokes = node_data.get(\"strokes\", [])\n",
    "    if strokes:\n",
    "        stroke = strokes[0]\n",
    "        feature[\"has_border\"] = 1\n",
    "        if \"color\" in stroke:\n",
    "            feature[\"border_r\"], feature[\"border_g\"], feature[\"border_b\"] = (\n",
    "                int(stroke[\"color\"].get(\"r\", 0) * 255),\n",
    "                int(stroke[\"color\"].get(\"g\", 0) * 255),\n",
    "                int(stroke[\"color\"].get(\"b\", 0) * 255),\n",
    "            )\n",
    "        feature[\"border_opacity\"] = stroke.get(\"opacity\", 0)\n",
    "    \n",
    "    # Extract border radius\n",
    "    br_top_left = node_data.get(\"topLeftRadius\", 0)\n",
    "    br_top_right = node_data.get(\"topRightRadius\", 0)\n",
    "    br_bottom_left = node_data.get(\"bottomLeftRadius\", 0)\n",
    "    br_bottom_right = node_data.get(\"bottomRightRadius\", 0)\n",
    "    \n",
    "    if any([br_top_left, br_top_right, br_bottom_left, br_bottom_right]):\n",
    "        feature[\"border_radius\"] = (br_top_left + br_top_right + br_bottom_left + br_bottom_right) / 4\n",
    "    \n",
    "    # Extract shadow\n",
    "    effects = node_data.get(\"effects\", [])\n",
    "    for effect in effects:\n",
    "        if effect.get(\"type\") == \"DROP_SHADOW\":\n",
    "            feature[\"has_shadow\"] = 1\n",
    "            if \"color\" in effect:\n",
    "                feature[\"shadow_r\"], feature[\"shadow_g\"], feature[\"shadow_b\"] = (\n",
    "                    int(effect[\"color\"].get(\"r\", 0) * 255),\n",
    "                    int(effect[\"color\"].get(\"g\", 0) * 255),\n",
    "                    int(effect[\"color\"].get(\"b\", 0) * 255),\n",
    "                )\n",
    "            feature[\"shadow_radius\"] = effect.get(\"radius\", 0)\n",
    "            break  \n",
    "    \n",
    "    features.append(feature)\n",
    "    \n",
    "    for child in children:\n",
    "        features.extend(extract_features(child, depth=depth+1, parent_tag=node_type, sibling_count=len(children)-1))\n",
    "    \n",
    "    return features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing test_json\\converted_output.json...\n",
      "Extracted features from all JSON files have been saved to figma_dataset.csv\n"
     ]
    }
   ],
   "source": [
    "# Folder containing JSON files\n",
    "data_folder = \"test_json\"\n",
    "output_csv_file = \"figma_dataset.csv\"\n",
    "\n",
    "normalize_columns = [\n",
    "    \"area\",\n",
    "    \"word_count\",\n",
    "    \"text_length\",\n",
    "    \"font_size\",\n",
    "    \"sibling_count\",\n",
    "    \"num_children\",\n",
    "    \"height\",\n",
    "    \"width\",\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "# If the output CSV exists, remove it so we start fresh\n",
    "if os.path.exists(output_csv_file):\n",
    "    os.remove(output_csv_file)\n",
    "\n",
    "# Flag to write header only for the first batch\n",
    "first_batch = True\n",
    "\n",
    "# Iterate over all JSON files in the data folder\n",
    "for filename in os.listdir(data_folder):\n",
    "    if filename.endswith(\".json\"):\n",
    "        file_path = os.path.join(data_folder, filename)\n",
    "        print(f\"Processing {file_path}...\")\n",
    "        \n",
    "        with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "            data = json.load(file)\n",
    "        \n",
    "        # Extract features using the recursive function starting at the root\n",
    "        features_list = extract_features(data, depth=0, parent_tag=None, sibling_count=0)\n",
    "        if not features_list:\n",
    "            continue  # Skip if no features extracted\n",
    "        \n",
    "        df = pd.DataFrame(features_list)\n",
    "        \n",
    "        # Normalize positions per JSON file to avoid cross-file influence\n",
    "        min_x = df['x'].min() if df['x'].notnull().any() else 0\n",
    "        min_y = df['y'].min() if df['y'].notnull().any() else 0\n",
    "        df['x_normalized'] = df['x'] - min_x\n",
    "        df['y_normalized'] = df['y'] - min_y\n",
    "        \n",
    "        df['x_center'] = df['x'] + df['width'] / 2\n",
    "        df['y_center'] = df['y'] + df['height'] / 2\n",
    "        \n",
    "        # Attempt to compute total dimensions using a BODY tag if available\n",
    "        body_node = df[df['tag'] == 'BODY']\n",
    "        if not body_node.empty:\n",
    "            total_width = body_node.iloc[0]['width']\n",
    "            total_height = body_node.iloc[0]['height']\n",
    "        else:\n",
    "            total_width = (df['x'] + df['width']).max()\n",
    "            total_height = (df['y'] + df['height']).max()\n",
    "        \n",
    "        # Avoid division by zero\n",
    "        if total_width and total_height:\n",
    "            df['x_quarter'] = df['x_center'] / total_width\n",
    "            df['y_quarter'] = df['y_center'] / total_height\n",
    "        else:\n",
    "            df['x_quarter'] = None\n",
    "            df['y_quarter'] = None\n",
    "        \n",
    "        df['aspect_ratio'] = df.apply(\n",
    "            lambda row: row['width'] / row['height'] if row['height'] and row['height'] != 0 else None, axis=1\n",
    "        )\n",
    "        df['area'] = df['width'] * df['height']\n",
    "        if total_width:\n",
    "            df['normalized_width'] = df['width'] / total_width\n",
    "        else:\n",
    "            df['normalized_width'] = None\n",
    "        if total_height:\n",
    "            df['normalized_height'] = df['height'] / total_height\n",
    "        else:\n",
    "            df['normalized_height'] = None\n",
    "\n",
    "\n",
    "        df = df.drop(columns=['x'])\n",
    "        df = df.drop(columns=['y'])\n",
    "        df = df.drop(columns=['x_normalized'])\n",
    "        df = df.drop(columns=['y_normalized'])\n",
    "        df = df.drop(columns=['x_center'])\n",
    "        df = df.drop(columns=['y_center'])\n",
    "\n",
    "\n",
    "        # Append this batch to the CSV file\n",
    "\n",
    "\n",
    "        # Compute min and max for each column\n",
    "        min_max_values = {col: (df[col].min(), df[col].max()) for col in normalize_columns}\n",
    "\n",
    "        # Apply Min-Max normalization (scaling between 0 and 1)\n",
    "        for col in normalize_columns:\n",
    "            min_val, max_val = min_max_values[col]\n",
    "            if max_val > min_val:  # Avoid division by zero\n",
    "                df[col] = (df[col] - min_val) / (max_val - min_val)\n",
    "            else:\n",
    "                df[col] = 0  # If min and max are the same, set to 0\n",
    "\n",
    "        \n",
    "        df.to_csv(output_csv_file, mode='a', header=first_batch, index=False)\n",
    "        first_batch = False\n",
    "\n",
    "print(f\"Extracted features from all JSON files have been saved to {output_csv_file}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
