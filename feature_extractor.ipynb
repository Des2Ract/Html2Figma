{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(node, depth=0, parent_tag=None, sibling_count=0):\n",
    "    features = []\n",
    "    \n",
    "    tag = node.get(\"tag\", \"NONE\")\n",
    "    node_data = node.get(\"node\", {})\n",
    "    node_type = str(node_data.get(\"type\", \"NONE\"))\n",
    "\n",
    "    text = node_data.get(\"characters\", \"NONE\")\n",
    "    text_length = len(text) if text != \"NONE\" else 0\n",
    "    word_count = len(text.split()) if text != \"NONE\" else 0\n",
    "    contains_number = any(ch.isdigit() for ch in text) if text != \"NONE\" else 0\n",
    "    contains_special_chars = any(not ch.isalnum() and not ch.isspace() for ch in text) if text != \"NONE\" else 0\n",
    "    \n",
    "    children = node.get(\"children\", [])\n",
    "    num_children = len(children)\n",
    "    is_leaf = 1 if num_children == 0 else 0\n",
    "    \n",
    "    feature = {\n",
    "        \"tag\": tag,\n",
    "        \"type\": node_type,\n",
    "        \"x\": node_data.get(\"x\", \"NONE\"),\n",
    "        \"y\": node_data.get(\"y\", \"NONE\"),\n",
    "        \"width\": node_data.get(\"width\", \"NONE\"),\n",
    "        \"height\": node_data.get(\"height\", \"NONE\"),\n",
    "        \"characters\": text,\n",
    "        \"depth\": depth,\n",
    "        \"num_children\": num_children,\n",
    "        \"parent_tag\": parent_tag if parent_tag is not None else \"NONE\",\n",
    "        \"sibling_count\": sibling_count,\n",
    "        \"is_leaf\": is_leaf,\n",
    "        \"font_size\": node_data.get(\"fontSize\", \"NONE\"),\n",
    "        \"font_weight\": node_data.get(\"fontName\", {}).get(\"style\", \"NONE\") if node_data.get(\"fontName\") else \"NONE\",\n",
    "        \"color_r\": 0, \"color_g\": 0, \"color_b\": 0,\n",
    "        \"background_r\": 0, \"background_g\": 0, \"background_b\": 0,\n",
    "        \"border_radius\": \"NONE\",\n",
    "        \"border_type\": \"NONE\",\n",
    "        \"border_r\": 0, \"border_g\": 0, \"border_b\": 0,\n",
    "        \"border_opacity\": \"NONE\",\n",
    "        \"border_weight\": node_data.get(\"strokeWeight\", \"NONE\"),\n",
    "        \"shadow_type\": \"NONE\",\n",
    "        \"shadow_r\": 0, \"shadow_g\": 0, \"shadow_b\": 0,\n",
    "        \"shadow_offset\": \"NONE\",\n",
    "        \"shadow_radius\": \"NONE\",\n",
    "        \"text_length\": text_length,\n",
    "        \"word_count\": word_count,\n",
    "        \"contains_number\": 1 if contains_number else 0,\n",
    "        \"contains_special_chars\": 1 if contains_special_chars else 0,\n",
    "    }\n",
    "    \n",
    "    fills = node_data.get(\"fills\", [])\n",
    "    for fill in fills:\n",
    "        if fill.get(\"type\") == \"SOLID\" and \"color\" in fill:\n",
    "            feature[\"color_r\"] = int(fill[\"color\"].get(\"r\", 0) * 255)\n",
    "            feature[\"color_g\"] = int(fill[\"color\"].get(\"g\", 0) * 255)\n",
    "            feature[\"color_b\"] = int(fill[\"color\"].get(\"b\", 0) * 255)\n",
    "            feature[\"background_r\"] = feature[\"color_r\"]\n",
    "            feature[\"background_g\"] = feature[\"color_g\"]\n",
    "            feature[\"background_b\"] = feature[\"color_b\"]\n",
    "            break  \n",
    "    \n",
    "    strokes = node_data.get(\"strokes\", [])\n",
    "    if strokes:\n",
    "        stroke = strokes[0]\n",
    "        feature[\"border_type\"] = stroke.get(\"type\", \"NONE\")\n",
    "        if \"color\" in stroke:\n",
    "            feature[\"border_r\"] = int(stroke[\"color\"].get(\"r\", 0) * 255)\n",
    "            feature[\"border_g\"] = int(stroke[\"color\"].get(\"g\", 0) * 255)\n",
    "            feature[\"border_b\"] = int(stroke[\"color\"].get(\"b\", 0) * 255)\n",
    "        feature[\"border_opacity\"] = stroke.get(\"opacity\", \"NONE\")\n",
    "    \n",
    "    br_top_left = node_data.get(\"topLeftRadius\", \"NONE\")\n",
    "    br_top_right = node_data.get(\"topRightRadius\", \"NONE\")\n",
    "    br_bottom_left = node_data.get(\"bottomLeftRadius\", \"NONE\")\n",
    "    br_bottom_right = node_data.get(\"bottomRightRadius\", \"NONE\")\n",
    "    if all(v != \"NONE\" for v in [br_top_left, br_top_right, br_bottom_left, br_bottom_right]):\n",
    "        feature[\"border_radius\"] = (br_top_left + br_top_right + br_bottom_left + br_bottom_right) / 4\n",
    "    \n",
    "    effects = node_data.get(\"effects\", [])\n",
    "    for effect in effects:\n",
    "        if effect.get(\"type\") == \"DROP_SHADOW\":\n",
    "            feature[\"shadow_type\"] = \"DROP_SHADOW\"\n",
    "            if \"color\" in effect:\n",
    "                feature[\"shadow_r\"] = int(effect[\"color\"].get(\"r\", 0) * 255)\n",
    "                feature[\"shadow_g\"] = int(effect[\"color\"].get(\"g\", 0) * 255)\n",
    "                feature[\"shadow_b\"] = int(effect[\"color\"].get(\"b\", 0) * 255)\n",
    "            feature[\"shadow_offset\"] = effect.get(\"offset\", \"NONE\")\n",
    "            feature[\"shadow_radius\"] = effect.get(\"radius\", \"NONE\")\n",
    "            break  \n",
    "    \n",
    "    features.append(feature)\n",
    "    \n",
    "    for child in children:\n",
    "        features.extend(extract_features(child, depth=depth+1, parent_tag=node_type, sibling_count=len(children)-1))\n",
    "    \n",
    "    return features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing json_data\\figmaTree_4.json...\n",
      "Extracted features from all JSON files have been saved to features_data.csv\n"
     ]
    }
   ],
   "source": [
    "# Folder containing JSON files\n",
    "data_folder = \"json_data\"\n",
    "output_csv_file = \"features_data.csv\"\n",
    "\n",
    "# If the output CSV exists, remove it so we start fresh\n",
    "if os.path.exists(output_csv_file):\n",
    "    os.remove(output_csv_file)\n",
    "\n",
    "# Flag to write header only for the first batch\n",
    "first_batch = True\n",
    "\n",
    "# Iterate over all JSON files in the data folder\n",
    "for filename in os.listdir(data_folder):\n",
    "    if filename.endswith(\".json\"):\n",
    "        file_path = os.path.join(data_folder, filename)\n",
    "        print(f\"Processing {file_path}...\")\n",
    "        \n",
    "        with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "            data = json.load(file)\n",
    "        \n",
    "        # Extract features using the recursive function starting at the root\n",
    "        features_list = extract_features(data, depth=0, parent_tag=None, sibling_count=0)\n",
    "        if not features_list:\n",
    "            continue  # Skip if no features extracted\n",
    "        \n",
    "        df = pd.DataFrame(features_list)\n",
    "        \n",
    "        # Normalize positions per JSON file to avoid cross-file influence\n",
    "        min_x = df['x'].min() if df['x'].notnull().any() else 0\n",
    "        min_y = df['y'].min() if df['y'].notnull().any() else 0\n",
    "        df['x_normalized'] = df['x'] - min_x\n",
    "        df['y_normalized'] = df['y'] - min_y\n",
    "        \n",
    "        df['x_center'] = df['x'] + df['width'] / 2\n",
    "        df['y_center'] = df['y'] + df['height'] / 2\n",
    "        \n",
    "        # Attempt to compute total dimensions using a BODY tag if available\n",
    "        body_node = df[df['tag'] == 'BODY']\n",
    "        if not body_node.empty:\n",
    "            total_width = body_node.iloc[0]['width']\n",
    "            total_height = body_node.iloc[0]['height']\n",
    "        else:\n",
    "            total_width = (df['x'] + df['width']).max()\n",
    "            total_height = (df['y'] + df['height']).max()\n",
    "        \n",
    "        # Avoid division by zero\n",
    "        if total_width and total_height:\n",
    "            df['x_quarter'] = df['x_center'] / total_width\n",
    "            df['y_quarter'] = df['y_center'] / total_height\n",
    "        else:\n",
    "            df['x_quarter'] = None\n",
    "            df['y_quarter'] = None\n",
    "        \n",
    "        df['aspect_ratio'] = df.apply(\n",
    "            lambda row: row['width'] / row['height'] if row['height'] and row['height'] != 0 else None, axis=1\n",
    "        )\n",
    "        df['area'] = df['width'] * df['height']\n",
    "        if total_width:\n",
    "            df['normalized_width'] = df['width'] / total_width\n",
    "        else:\n",
    "            df['normalized_width'] = None\n",
    "        if total_height:\n",
    "            df['normalized_height'] = df['height'] / total_height\n",
    "        else:\n",
    "            df['normalized_height'] = None\n",
    "\n",
    "\n",
    "        df = df.drop(columns=['x'])\n",
    "        df = df.drop(columns=['y'])\n",
    "        df = df.drop(columns=['x_normalized'])\n",
    "        df = df.drop(columns=['y_normalized'])\n",
    "        df = df.drop(columns=['x_center'])\n",
    "        df = df.drop(columns=['y_center'])\n",
    "\n",
    "\n",
    "        # Append this batch to the CSV file\n",
    "        \n",
    "        df.to_csv(output_csv_file, mode='a', header=first_batch, index=False)\n",
    "        first_batch = False\n",
    "\n",
    "print(f\"Extracted features from all JSON files have been saved to {output_csv_file}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
