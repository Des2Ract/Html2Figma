{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kareem alaa\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\kareem alaa\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import time\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from torch.amp import autocast, GradScaler\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sentence_transformers import SentenceTransformer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable cuDNN benchmarking for faster training\n",
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Load dataset and remove rows with '-' in the tag column\n",
    "df = pd.read_csv(\"../../feature_extraction/figma_dataset.csv\")\n",
    "df = df[~df['tag'].str.contains('-')]\n",
    "\n",
    "unique_tags = df['tag'].unique().tolist()\n",
    "\n",
    "# Define tag replacement rules\n",
    "txt_tags = ['B', 'CAPTION', 'EM', 'FIGCAPTION', 'I', 'H1', 'H2', 'H3', 'H4', 'H5', 'H6', \n",
    "            'LABEL', 'LI', 'TIME', 'TD', 'TH', 'U', 'P',  'SPAN', 'A', 'TXT', 'SMALL', 'ADDRESS', 'STRONG',\n",
    "            'SUMMARY', 'SUP']\n",
    "\n",
    "div_tags = ['ARTICLE', 'FIGURE', 'FOOTER', 'HEADER', 'MAIN', 'NAV', 'OL', 'UL', 'FORM', 'DETAILS', 'SECTION']\n",
    "\n",
    "\n",
    "button_tags = ['SELECT']\n",
    "\n",
    "# Apply replacements\n",
    "df['tag'] = df['tag'].apply(\n",
    "    lambda x: 'TEXT' if x in txt_tags else \n",
    "              'DIV' if x in div_tags else \n",
    "              'BUTTON' if x in div_tags else \n",
    "              x\n",
    ")\n",
    "\n",
    "allowed_tags = [\"DIV\", \"BUTTON\", \"INPUT\"]\n",
    "df = df[df[\"tag\"].isin(allowed_tags)]\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "\n",
    "columns_to_drop = [\n",
    "    'type', 'num_children', 'parent_tag', 'parent_tag_html', 'prev_sibling_tag', 'parent_prev_sibling_tag', \n",
    "    'sibling_count', 'has_background_color', 'text_length', 'nearest_text_distance', 'nearest_image_distance']\n",
    "\n",
    "# Safely drop columns that exist\n",
    "for col in columns_to_drop:\n",
    "    if col in df.columns:\n",
    "        df = df.drop(columns=[col])\n",
    "\n",
    "# Save the modified dataframe to a new Excel file\n",
    "df.to_csv('cleaned_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating embeddings for nearest_text_content...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1920/1920 [00:23<00:00, 82.81it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding shape: (61420, 384)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 4. Generate embeddings\n",
    "\n",
    "sentence_model = SentenceTransformer('all-MiniLM-L6-v2')  \n",
    "text_contents = df['nearest_text_content'].fillna('').tolist()\n",
    "\n",
    "\n",
    "print(\"Generating embeddings for nearest_text_content...\")\n",
    "text_embeddings = sentence_model.encode(text_contents, show_progress_bar=True)\n",
    "print(f\"Embedding shape: {text_embeddings.shape}\")  # Should be (n_samples, embedding_dim)\n",
    "\n",
    "# 5. Create column names for the embeddings\n",
    "embedding_dim = text_embeddings.shape[1]\n",
    "embedding_cols = [f'text_embedding_{i}' for i in range(embedding_dim)]\n",
    "\n",
    "# 6. Add embeddings to the dataframe\n",
    "embedding_df = pd.DataFrame(text_embeddings, columns=embedding_cols)\n",
    "df_with_embeddings = pd.concat([df, embedding_df], axis=1)\n",
    "\n",
    "# 7. Drop the original text content column since we now have embeddings\n",
    "df_with_embeddings = df_with_embeddings.drop(columns=['nearest_text_content'])\n",
    "\n",
    "# 8. Optionally, handle the nearest_image_size column\n",
    "# If it's not numeric, you might want to process it separately or drop it\n",
    "if 'nearest_image_size' in df_with_embeddings.columns and df_with_embeddings['nearest_image_size'].dtype == 'object':\n",
    "    # If it contains dimensions like '324x240', extract features\n",
    "    try:\n",
    "        # Try to convert to numeric directly\n",
    "        df_with_embeddings['nearest_image_size'] = pd.to_numeric(df_with_embeddings['nearest_image_size'])\n",
    "    except:\n",
    "        # If that fails, it might be in the format of dimensions, so drop it or process it\n",
    "        df_with_embeddings = df_with_embeddings.drop(columns=['nearest_image_size'])\n",
    "\n",
    "# 9. Save the dataframe with embeddings\n",
    "df = df_with_embeddings\n",
    "\n",
    "# 10. Now continue with model training as before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Separate features and target\n",
    "y = df[\"tag\"]\n",
    "X = df.drop(columns=[\"tag\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Identify categorical and continuous columns\n",
    "categorical_cols = []\n",
    "continuous_cols = [col for col in X.columns if col not in categorical_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ohe_encoder.pkl']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Process categorical features with OneHotEncoder instead of LabelEncoder\n",
    "X[categorical_cols] = X[categorical_cols].astype(str).fillna('unknown')\n",
    "ohe = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "X_cat_encoded = ohe.fit_transform(X[categorical_cols])\n",
    "joblib.dump(ohe, \"ohe_encoder.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['imputer.pkl']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Better missing value handling with imputer\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "X_continuous_imputed = imputer.fit_transform(X[continuous_cols])\n",
    "joblib.dump(imputer, \"imputer.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['scaler.pkl']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scale continuous features\n",
    "scaler = StandardScaler()\n",
    "X_continuous_scaled = scaler.fit_transform(X_continuous_imputed)\n",
    "joblib.dump(scaler, \"scaler.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine one-hot encoded categorical features with scaled continuous features\n",
    "X_processed = np.concatenate([X_cat_encoded, X_continuous_scaled], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['label_encoder.pkl']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4. Encode target labels\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "joblib.dump(label_encoder, \"label_encoder.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# Count occurrences of each class\n",
    "class_counts = Counter(y_encoded)\n",
    "\n",
    "# Find classes with only 1 sample\n",
    "rare_classes = [cls for cls, count in class_counts.items() if count < 2]\n",
    "\n",
    "# Duplicate rare class samples\n",
    "for cls in rare_classes:\n",
    "    idx = np.where(y_encoded == cls)[0][0]  # Get the index of the rare sample\n",
    "    original_class_name = label_encoder.inverse_transform([cls])[0]  # Convert back to original label\n",
    "    print(f\"Duplicating class '{original_class_name}' (only 1 sample present).\")\n",
    "\n",
    "    X_processed = np.vstack([X_processed, X_processed[idx]])  # Duplicate features\n",
    "    y_encoded = np.append(y_encoded, y_encoded[idx])  # Duplicate label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Train/test split - remove stratification if there are classes with too few samples\n",
    "unique_counts = np.unique(y_encoded, return_counts=True)\n",
    "min_samples = min(unique_counts[1])\n",
    "\n",
    "if min_samples < 2:\n",
    "    print(f\"Warning: The least populated class has only {min_samples} sample(s). Removing stratification.\")\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_processed, y_encoded, test_size=0.2, random_state=42\n",
    "    )\n",
    "else:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_processed, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Move GPU setup earlier\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert data to tensors\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataset and dataloaders\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, \n",
    "    batch_size=256,  # Larger batch size\n",
    "    shuffle=True, \n",
    "    num_workers=4,   # Parallel loading\n",
    "    pin_memory=True  # Faster data transfer to GPU\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing class weights...\n"
     ]
    }
   ],
   "source": [
    "# Compute class weights\n",
    "print(\"Computing class weights...\")\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n",
    "class_weights = torch.tensor(class_weights, dtype=torch.float32).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Define improved model architecture with proper input size\n",
    "class ImprovedTagClassifier(nn.Module):\n",
    "    def __init__(self, input_size, output_size, dropout_rate=0.3):\n",
    "        super(ImprovedTagClassifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 256)\n",
    "        self.bn1 = nn.BatchNorm1d(256)\n",
    "        self.fc2 = nn.Linear(256, 256)\n",
    "        self.bn2 = nn.BatchNorm1d(256)\n",
    "        self.fc3 = nn.Linear(256, 128)\n",
    "        self.bn3 = nn.BatchNorm1d(128)\n",
    "        self.fc4 = nn.Linear(128, output_size)\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.dropout(self.relu(self.bn1(self.fc1(x))))\n",
    "        x = self.dropout(self.relu(self.bn2(self.fc2(x))))\n",
    "        x = self.dropout(self.relu(self.bn3(self.fc3(x))))\n",
    "        logits = self.fc4(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing model...\n"
     ]
    }
   ],
   "source": [
    "# Initialize model\n",
    "print(\"Initializing model...\")\n",
    "input_size = X_train.shape[1]\n",
    "output_size = len(label_encoder.classes_)\n",
    "model = ImprovedTagClassifier(input_size, output_size).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=5, factor=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Setup mixed precision training\n",
    "scaler = GradScaler(device='cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "Epoch [5/200], Loss: 0.2753, Time: 6.59s\n",
      "Epoch [10/200], Loss: 0.2147, Time: 5.70s\n",
      "Epoch [15/200], Loss: 0.1849, Time: 5.73s\n",
      "Epoch [20/200], Loss: 0.1714, Time: 7.34s\n",
      "Epoch [25/200], Loss: 0.1581, Time: 6.30s\n",
      "Epoch [30/200], Loss: 0.1434, Time: 6.02s\n",
      "Epoch [35/200], Loss: 0.1414, Time: 6.10s\n",
      "Epoch [40/200], Loss: 0.1365, Time: 6.47s\n",
      "Epoch [45/200], Loss: 0.1132, Time: 7.43s\n",
      "Epoch [50/200], Loss: 0.1134, Time: 7.42s\n",
      "Epoch [55/200], Loss: 0.1020, Time: 7.17s\n",
      "Epoch [60/200], Loss: 0.1086, Time: 5.97s\n",
      "Epoch [65/200], Loss: 0.1011, Time: 6.20s\n",
      "Epoch [70/200], Loss: 0.0992, Time: 6.67s\n",
      "Epoch [75/200], Loss: 0.0933, Time: 6.75s\n",
      "Epoch [80/200], Loss: 0.0933, Time: 5.82s\n",
      "Epoch [85/200], Loss: 0.0853, Time: 7.24s\n",
      "Epoch [90/200], Loss: 0.0921, Time: 5.59s\n",
      "Epoch [95/200], Loss: 0.0786, Time: 5.20s\n",
      "Epoch [100/200], Loss: 0.0760, Time: 5.20s\n",
      "Epoch [105/200], Loss: 0.0714, Time: 5.63s\n",
      "Epoch [110/200], Loss: 0.0737, Time: 5.33s\n",
      "Epoch [115/200], Loss: 0.0715, Time: 5.63s\n",
      "Epoch [120/200], Loss: 0.0677, Time: 5.81s\n",
      "Epoch [125/200], Loss: 0.0719, Time: 5.24s\n",
      "Epoch [130/200], Loss: 0.0670, Time: 5.32s\n",
      "Epoch [135/200], Loss: 0.0616, Time: 5.61s\n",
      "Epoch [140/200], Loss: 0.0622, Time: 5.60s\n",
      "Epoch [145/200], Loss: 0.0625, Time: 6.16s\n",
      "Early stopping at epoch 145\n"
     ]
    }
   ],
   "source": [
    "# 9. Training loop with timing and early stopping\n",
    "print(\"Starting training...\")\n",
    "best_loss = float('inf')\n",
    "patience = 10\n",
    "counter = 0\n",
    "early_stop = False\n",
    "start_time = time.time()\n",
    "\n",
    "num_epochs = 200\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_start = time.time()\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    \n",
    "    for batch_X, batch_y in train_loader:\n",
    "        # Move batch to device\n",
    "        batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Use mixed precision for faster training\n",
    "        with torch.amp.autocast('cuda', enabled=device.type=='cuda'):\n",
    "            outputs = model(batch_X)\n",
    "            loss = criterion(outputs, batch_y)\n",
    "        \n",
    "        # Scale gradients and optimize\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "    \n",
    "    avg_loss = epoch_loss / len(train_loader)\n",
    "    scheduler.step(avg_loss)\n",
    "    \n",
    "    epoch_time = time.time() - epoch_start\n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        print(f\"Epoch [{epoch + 1}/{num_epochs}], Loss: {avg_loss:.4f}, Time: {epoch_time:.2f}s\")\n",
    "    \n",
    "    # Early stopping\n",
    "    if avg_loss < best_loss:\n",
    "        best_loss = avg_loss\n",
    "        counter = 0\n",
    "        torch.save(model.state_dict(), \"best_tag_classifier.pth\")\n",
    "    else:\n",
    "        counter += 1\n",
    "        if counter >= patience:\n",
    "            print(f\"Early stopping at epoch {epoch+1}\")\n",
    "            early_stop = True\n",
    "    \n",
    "    if early_stop:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training time: 890.18 seconds\n"
     ]
    }
   ],
   "source": [
    "# Save the trained model\n",
    "torch.save(model.state_dict(), \"tag_classifier.pth\")\n",
    "total_time = time.time() - start_time\n",
    "print(f\"Total training time: {total_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model...\n",
      "\n",
      "Accuracy: 0.9399\n"
     ]
    }
   ],
   "source": [
    "# 10. Evaluation on the test set\n",
    "print(\"Evaluating model...\")\n",
    "model.load_state_dict(torch.load(\"best_tag_classifier.pth\"))  # Load best model\n",
    "model.eval()\n",
    "\n",
    "# Process test data in batches for memory efficiency\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "test_loader = DataLoader(test_dataset, batch_size=256)\n",
    "\n",
    "all_predictions = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_X, batch_y in test_loader:\n",
    "        batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "        outputs = model(batch_X)\n",
    "        _, predictions = torch.max(outputs, 1)\n",
    "        all_predictions.extend(predictions.cpu().numpy())\n",
    "        all_labels.extend(batch_y.cpu().numpy())\n",
    "\n",
    "y_pred = np.array(all_predictions)\n",
    "y_test_np = np.array(all_labels)\n",
    "\n",
    "accuracy = accuracy_score(y_test_np, y_pred)\n",
    "print(f\"\\nAccuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      BUTTON       0.26      0.56      0.35       336\n",
      "         DIV       0.99      0.95      0.97     11831\n",
      "       INPUT       0.74      0.89      0.81       117\n",
      "\n",
      "    accuracy                           0.94     12284\n",
      "   macro avg       0.66      0.80      0.71     12284\n",
      "weighted avg       0.96      0.94      0.95     12284\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(\n",
    "    y_test_np, \n",
    "    y_pred,\n",
    "    labels=np.unique(y_test_np),\n",
    "    target_names=label_encoder.inverse_transform(np.unique(y_test_np))\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Analyzing feature importance...\n",
      "\n",
      "Top 30 most important features:\n",
      "width: 0.4580\n",
      "depth: 0.3321\n",
      "is_leaf: 0.2601\n",
      "aspect_ratio: 0.2353\n",
      "distinct_background: 0.2286\n",
      "nearest_image_size: 0.1840\n",
      "total_descendants: 0.1440\n",
      "total_text_nodes: 0.1341\n",
      "total_text_length: 0.0990\n",
      "text_embedding_319: 0.0886\n",
      "text_embedding_376: 0.0779\n",
      "text_embedding_145: 0.0774\n",
      "text_embedding_213: 0.0768\n",
      "text_embedding_290: 0.0768\n",
      "text_embedding_0: 0.0767\n",
      "text_embedding_82: 0.0765\n",
      "text_embedding_222: 0.0761\n",
      "text_embedding_94: 0.0758\n",
      "text_embedding_226: 0.0754\n",
      "text_embedding_199: 0.0753\n",
      "text_embedding_128: 0.0753\n",
      "text_embedding_190: 0.0751\n",
      "text_embedding_32: 0.0748\n",
      "text_embedding_101: 0.0745\n",
      "text_embedding_291: 0.0744\n",
      "text_embedding_184: 0.0743\n",
      "text_embedding_52: 0.0741\n",
      "text_embedding_312: 0.0740\n",
      "text_embedding_20: 0.0740\n",
      "text_embedding_162: 0.0740\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Print feature importances from the model\n",
    "print(\"\\nAnalyzing feature importance...\")\n",
    "with torch.no_grad():\n",
    "    weights = model.fc1.weight.cpu().numpy()\n",
    "    importance = np.abs(weights).mean(axis=0)\n",
    "    \n",
    "    # Get feature names (both categorical encoded and continuous)\n",
    "    cat_feature_names = ohe.get_feature_names_out(categorical_cols)\n",
    "    all_feature_names = np.concatenate([cat_feature_names, np.array(continuous_cols)])\n",
    "    \n",
    "    feature_importance = list(zip(all_feature_names, importance))\n",
    "    feature_importance.sort(key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    print(\"\\nTop 30 most important features:\")\n",
    "    for feature, imp in feature_importance[:30]:\n",
    "        print(f\"{feature}: {imp:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
