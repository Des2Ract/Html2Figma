{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset, WeightedRandomSampler\n",
    "import torch\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import joblib  # For saving encoders and scalers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Load dataset and remove rows with '-' in the tag column\n",
    "df = pd.read_csv(\"figma_dataset.csv\")\n",
    "df = df[~df['tag'].str.contains('-')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Separate features and target\n",
    "y = df[\"tag\"]\n",
    "X = df.drop(columns=[\"tag\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Identify categorical and continuous columns\n",
    "categorical_cols = []\n",
    "continuous_cols = [col for col in X.columns if col not in categorical_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process categorical features with LabelEncoder\n",
    "for col in categorical_cols:\n",
    "    X[col] = X[col].astype(str)\n",
    "    le = LabelEncoder()\n",
    "    X[col] = le.fit_transform(X[col])\n",
    "    # If you need to save individual encoders, consider saving them in a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['scaler.pkl']"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fill missing values in continuous columns and scale them\n",
    "X[continuous_cols] = X[continuous_cols].fillna(0)\n",
    "scaler = StandardScaler()\n",
    "X_continuous_scaled = scaler.fit_transform(X[continuous_cols])\n",
    "joblib.dump(scaler, \"scaler.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace continuous columns in X with their scaled values\n",
    "X_scaled = X.copy()\n",
    "X_scaled[continuous_cols] = X_continuous_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['label_encoder.pkl']"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4. Encode target labels\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "joblib.dump(label_encoder, \"label_encoder.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_encoded, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert data to PyTorch tensors\n",
    "# Note: X_train and X_test are DataFrames, so use .values to convert to NumPy arrays.\n",
    "X_train_tensor = torch.tensor(X_train.values, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
    "X_test_tensor = torch.tensor(X_test.values, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Define the Neural Network Model with non-linear activations between linear layers\n",
    "class TagClassifier(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(TagClassifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 64)  # First hidden layer\n",
    "        self.fc2 = nn.Linear(64, 128)           # Second hidden layer\n",
    "        self.fc3 = nn.Linear(128, 256)            # Third hidden layer\n",
    "        # self.fc4 = nn.Linear(256, 512)            # Fourth hidden layer\n",
    "        # self.fc5 = nn.Linear(512, 512)            # Fifth hidden layer\n",
    "        # self.fc6 = nn.Linear(512, 512)            # Sixth hidden layer\n",
    "        # self.fc7 = nn.Linear(512, 256)            # Seventh hidden layer\n",
    "        self.fc8 = nn.Linear(256, 128)           # Eighth hidden layer\n",
    "        self.fc9 = nn.Linear(128, output_size)   # Output layer\n",
    "        self.relu = nn.ReLU()                  # Non-linear activation\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.relu(self.fc3(x))\n",
    "        # x = self.relu(self.fc4(x))\n",
    "        # x = self.relu(self.fc5(x))\n",
    "        # x = self.relu(self.fc6(x))\n",
    "        # x = self.relu(self.fc7(x))\n",
    "        x = self.relu(self.fc8(x))\n",
    "        logits = self.fc9(x)  # No activation here: CrossEntropyLoss expects raw logits.\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model\n",
    "input_size = X_train_tensor.shape[1]\n",
    "output_size = len(label_encoder.classes_)\n",
    "model = TagClassifier(input_size, output_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()  # Internally applies softmax on logits\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a TensorDataset from the training tensors\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "\n",
    "# Define a DataLoader with a chosen batch size (e.g., 64)\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/100], Loss: 0.0763\n",
      "Epoch [20/100], Loss: 0.0068\n",
      "Epoch [30/100], Loss: 0.0008\n",
      "Epoch [40/100], Loss: 0.0001\n",
      "Epoch [50/100], Loss: 0.0000\n",
      "Epoch [60/100], Loss: 0.0000\n",
      "Epoch [70/100], Loss: 0.0000\n",
      "Epoch [80/100], Loss: 0.0000\n",
      "Epoch [90/100], Loss: 0.0000\n",
      "Epoch [100/100], Loss: 0.0000\n"
     ]
    }
   ],
   "source": [
    "# 9. Training loop\n",
    "\n",
    "# Create a DataLoader with mini-batches\n",
    "batch_size = 64\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 100\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    epoch_loss = 0.0\n",
    "\n",
    "    for batch_X, batch_y in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch_X)\n",
    "        loss = criterion(outputs, batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item() * batch_X.size(0)  # Accumulate loss weighted by batch size\n",
    "\n",
    "    # Compute average loss for the epoch\n",
    "    avg_loss = epoch_loss / len(train_dataset)\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f\"Epoch [{epoch + 1}/{num_epochs}], Loss: {avg_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model\n",
    "torch.save(model.state_dict(), \"tag_classifier.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy: 0.9997\n"
     ]
    }
   ],
   "source": [
    "# 10. Evaluation on the test set\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    outputs = model(X_test_tensor)\n",
    "    y_pred = torch.argmax(outputs, dim=1).numpy()\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"\\nAccuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       1.00      1.00      1.00      3118\n",
      "     ADDRESS       1.00      1.00      1.00        16\n",
      "     ARTICLE       1.00      1.00      1.00       178\n",
      "       ASIDE       1.00      0.83      0.91        12\n",
      "           B       1.00      1.00      1.00         6\n",
      "        BODY       1.00      1.00      1.00        22\n",
      "      BUTTON       1.00      1.00      1.00       357\n",
      "      CANVAS       1.00      1.00      1.00         2\n",
      "        DATA       1.00      1.00      1.00         1\n",
      "          DD       1.00      1.00      1.00         1\n",
      "         DEL       1.00      1.00      1.00         7\n",
      "     DETAILS       1.00      1.00      1.00         1\n",
      "         DIV       1.00      1.00      1.00     10568\n",
      "          DL       1.00      1.00      1.00         2\n",
      "          DT       1.00      1.00      1.00         2\n",
      "          EM       1.00      1.00      1.00        12\n",
      "  FIGCAPTION       1.00      1.00      1.00        22\n",
      "      FIGURE       1.00      0.99      1.00       158\n",
      "      FOOTER       1.00      1.00      1.00        71\n",
      "        FORM       1.00      1.00      1.00        24\n",
      "          H1       1.00      1.00      1.00        12\n",
      "          H2       1.00      1.00      1.00       324\n",
      "          H3       1.00      1.00      1.00       526\n",
      "          H4       1.00      1.00      1.00        67\n",
      "          H5       1.00      1.00      1.00        10\n",
      "          H6       1.00      1.00      1.00         9\n",
      "      HEADER       1.00      1.00      1.00       127\n",
      "      HGROUP       1.00      1.00      1.00         2\n",
      "          HR       1.00      0.98      0.99        47\n",
      "           I       1.00      1.00      1.00       115\n",
      "      IFRAME       1.00      1.00      1.00        37\n",
      "         IMG       1.00      1.00      1.00       699\n",
      "       INPUT       1.00      1.00      1.00       119\n",
      "       LABEL       1.00      1.00      1.00       114\n",
      "      LEGEND       0.00      0.00      0.00         1\n",
      "          LI       1.00      1.00      1.00      1052\n",
      "        MAIN       1.00      1.00      1.00        11\n",
      "         NAV       1.00      0.97      0.98        31\n",
      "      OBJECT       1.00      1.00      1.00         2\n",
      "          OL       1.00      1.00      1.00         6\n",
      "           P       1.00      1.00      1.00       455\n",
      "     PICTURE       1.00      1.00      1.00       313\n",
      "           S       1.00      1.00      1.00         3\n",
      "     SECTION       1.00      1.00      1.00       244\n",
      "      SELECT       1.00      1.00      1.00         1\n",
      "       SMALL       1.00      1.00      1.00         3\n",
      "      SOURCE       1.00      1.00      1.00         1\n",
      "        SPAN       1.00      1.00      1.00      3157\n",
      "      STRONG       1.00      0.97      0.99        35\n",
      "     SUMMARY       1.00      1.00      1.00         7\n",
      "         SUP       1.00      1.00      1.00         1\n",
      "         SVG       1.00      1.00      1.00       909\n",
      "       TABLE       1.00      1.00      1.00         4\n",
      "       TBODY       1.00      1.00      1.00         7\n",
      "          TD       1.00      1.00      1.00       167\n",
      "          TH       1.00      1.00      1.00        27\n",
      "       THEAD       1.00      1.00      1.00         5\n",
      "        TIME       1.00      1.00      1.00       128\n",
      "          TR       1.00      1.00      1.00        32\n",
      "         TXT       1.00      1.00      1.00      2882\n",
      "          UL       1.00      1.00      1.00       268\n",
      "      VECTOR       1.00      1.00      1.00         2\n",
      "       VIDEO       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           1.00     26548\n",
      "   macro avg       0.98      0.98      0.98     26548\n",
      "weighted avg       1.00      1.00      1.00     26548\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kareem alaa\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\kareem alaa\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\kareem alaa\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred,\n",
    "                            labels=np.unique(y_test),\n",
    "                            target_names=label_encoder.inverse_transform(np.unique(y_test))))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
