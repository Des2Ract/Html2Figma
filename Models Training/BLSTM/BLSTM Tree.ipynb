{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a8b1c463",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Creating tree metadata from figma_dataset_tree_blstm.h5...\n",
      "Found 1370 trees\n",
      "Found 11 unique tags\n",
      "First feature vector dimension: 831\n",
      "Unique feature vector dimensions: [831]\n",
      "Number of classes: 11\n",
      "Train trees: 959\n",
      "Validation trees: 205\n",
      "Test trees: 206\n",
      "Model initialized with input_dim=831, hidden_dim=128\n",
      "Starting training with tree-based BLSTM...\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/959 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x shape: torch.Size([831])\n",
      "h_sum shape: torch.Size([256])\n",
      "Combined input shape: torch.Size([1087])\n",
      "x shape: torch.Size([831])\n",
      "h_sum shape: torch.Size([256])\n",
      "Combined input shape: torch.Size([1087])\n",
      "x shape: torch.Size([831])\n",
      "h_sum shape: torch.Size([128])\n",
      "Combined input shape: torch.Size([959])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (1x959 and 1087x384)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 640\u001b[0m\n\u001b[0;32m    637\u001b[0m DATA_PATH \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfigma_dataset_tree_blstm.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# Use corrected dataset\u001b[39;00m\n\u001b[0;32m    638\u001b[0m MAX_TREES \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2000\u001b[39m\n\u001b[1;32m--> 640\u001b[0m model, label_encoder, test_metrics \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_tree_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mDATA_PATH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_trees\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mMAX_TREES\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    641\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining completed successfully!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[7], line 557\u001b[0m, in \u001b[0;36mtrain_tree_model\u001b[1;34m(data_path, model_config, max_trees)\u001b[0m\n\u001b[0;32m    555\u001b[0m trees \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrees\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m    556\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m tree \u001b[38;5;129;01min\u001b[39;00m trees:\n\u001b[1;32m--> 557\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[43msafe_tree_training_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtree\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    558\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m loss \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    559\u001b[0m         train_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\n",
      "Cell \u001b[1;32mIn[7], line 311\u001b[0m, in \u001b[0;36msafe_tree_training_step\u001b[1;34m(model, tree, criterion, optimizer, device)\u001b[0m\n\u001b[0;32m    309\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    310\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 311\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "Cell \u001b[1;32mIn[7], line 289\u001b[0m, in \u001b[0;36msafe_tree_training_step\u001b[1;34m(model, tree, criterion, optimizer, device)\u001b[0m\n\u001b[0;32m    286\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m    288\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m autocast():\n\u001b[1;32m--> 289\u001b[0m     logits, _ \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtree\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    290\u001b[0m     label \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([tree\u001b[38;5;241m.\u001b[39mlabel], dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m    291\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(logits, label)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[1;32mIn[7], line 253\u001b[0m, in \u001b[0;36mTreeBLSTM.forward\u001b[1;34m(self, tree)\u001b[0m\n\u001b[0;32m    252\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, tree):\n\u001b[1;32m--> 253\u001b[0m     h_forward, c_forward, h_backward, c_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtree\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    254\u001b[0m     h_combined \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([h_forward, h_backward], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    255\u001b[0m     h_combined \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(h_combined)\n",
      "Cell \u001b[1;32mIn[7], line 272\u001b[0m, in \u001b[0;36mTreeBLSTM._forward_backward\u001b[1;34m(self, node)\u001b[0m\n\u001b[0;32m    269\u001b[0m c_children_b \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    271\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m child \u001b[38;5;129;01min\u001b[39;00m node\u001b[38;5;241m.\u001b[39mchildren:\n\u001b[1;32m--> 272\u001b[0m     h_f, c_f, h_b, c_b \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchild\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    273\u001b[0m     h_children_f\u001b[38;5;241m.\u001b[39mappend(h_f)\n\u001b[0;32m    274\u001b[0m     c_children_f\u001b[38;5;241m.\u001b[39mappend(c_f)\n",
      "Cell \u001b[1;32mIn[7], line 279\u001b[0m, in \u001b[0;36mTreeBLSTM._forward_backward\u001b[1;34m(self, node)\u001b[0m\n\u001b[0;32m    276\u001b[0m     c_children_b\u001b[38;5;241m.\u001b[39mappend(c_b)\n\u001b[0;32m    278\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(node\u001b[38;5;241m.\u001b[39mfeature_vector, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m--> 279\u001b[0m h_f, c_f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward_cell\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mh_children_f\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc_children_f\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    280\u001b[0m h_b, c_b \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbackward_cell(x, h_children_b, c_children_b)\n\u001b[0;32m    281\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m h_f, c_f, h_b, c_b\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[1;32mIn[7], line 234\u001b[0m, in \u001b[0;36mTreeLSTMCell.forward\u001b[1;34m(self, x, h_children, c_children)\u001b[0m\n\u001b[0;32m    232\u001b[0m combined \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([x, h_sum], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    233\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCombined input shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcombined\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m# Debug\u001b[39;00m\n\u001b[1;32m--> 234\u001b[0m iou \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miou\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcombined\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    235\u001b[0m i, o, u \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mchunk(iou, \u001b[38;5;241m3\u001b[39m, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    236\u001b[0m i, o, u \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msigmoid(i), torch\u001b[38;5;241m.\u001b[39msigmoid(o), torch\u001b[38;5;241m.\u001b[39mtanh(u)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\nn\\modules\\linear.py:125\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (1x959 and 1087x384)"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gc\n",
    "import psutil\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import h5py\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "import json\n",
    "import time\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Memory monitoring function\n",
    "def print_memory_usage(printing=True):\n",
    "    process = psutil.Process(os.getpid())\n",
    "    memory_info = process.memory_info()\n",
    "    memory_gb = memory_info.rss / 1024**3\n",
    "    if printing:\n",
    "        print(f\"Memory usage: {memory_gb:.2f} GB\")\n",
    "    return memory_gb\n",
    "\n",
    "# Set memory limit and device\n",
    "MEMORY_LIMIT_GB = 7.5\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Initialize GradScaler for mixed precision\n",
    "scaler = GradScaler()\n",
    "\n",
    "class EarlyStopping:\n",
    "    \"\"\"Early stopping to prevent overfitting.\"\"\"\n",
    "    def __init__(self, patience=7, min_delta=0.0001, restore_best_weights=True):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.restore_best_weights = restore_best_weights\n",
    "        self.best_loss = None\n",
    "        self.counter = 0\n",
    "        self.best_weights = None\n",
    "        \n",
    "    def __call__(self, val_loss, model):\n",
    "        if self.best_loss is None:\n",
    "            self.best_loss = val_loss\n",
    "            self.save_checkpoint(model)\n",
    "        elif val_loss < self.best_loss - self.min_delta:\n",
    "            self.best_loss = val_loss\n",
    "            self.counter = 0\n",
    "            self.save_checkpoint(model)\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            \n",
    "        if self.counter >= self.patience:\n",
    "            if self.restore_best_weights:\n",
    "                model.load_state_dict(self.best_weights)\n",
    "            return True\n",
    "        return False\n",
    "    \n",
    "    def save_checkpoint(self, model):\n",
    "        \"\"\"Save model checkpoint.\"\"\"\n",
    "        self.best_weights = model.state_dict().copy()\n",
    "\n",
    "class TreeNode:\n",
    "    def __init__(self, feature_vector, label, node_index, parent_index):\n",
    "        self.feature_vector = feature_vector\n",
    "        self.label = label\n",
    "        self.node_index = node_index\n",
    "        self.parent_index = parent_index\n",
    "        self.children = []\n",
    "\n",
    "class LazyFigmaTreeDataset(Dataset):\n",
    "    \"\"\"Lazy loading dataset for Figma tree structures.\"\"\"\n",
    "    \n",
    "    def __init__(self, data_path, tree_metadata, label_encoder, cache_size=100, expected_dim=831):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            data_path: Path to the HDF5 data file\n",
    "            tree_metadata: List of dicts with tree info (tree_id, node_indices)\n",
    "            label_encoder: Fitted label encoder\n",
    "            cache_size: Number of trees to keep in memory cache\n",
    "            expected_dim: Expected feature vector dimension\n",
    "        \"\"\"\n",
    "        self.data_path = data_path\n",
    "        self.tree_metadata = tree_metadata\n",
    "        self.label_encoder = label_encoder\n",
    "        self.cache_size = cache_size\n",
    "        self.expected_dim = expected_dim\n",
    "        self.cache = {}\n",
    "        self.cache_order = []\n",
    "        \n",
    "        self._file_handle = None\n",
    "        self._open_file()\n",
    "    \n",
    "    def _open_file(self):\n",
    "        \"\"\"Open file handle for HDF5.\"\"\"\n",
    "        self._file_handle = h5py.File(self.data_path, 'r')\n",
    "    \n",
    "    def _close_file(self):\n",
    "        \"\"\"Close file handle.\"\"\"\n",
    "        if self._file_handle is not None:\n",
    "            self._file_handle.close()\n",
    "            self._file_handle = None\n",
    "    \n",
    "    def __del__(self):\n",
    "        \"\"\"Cleanup file handle.\"\"\"\n",
    "        self._close_file()\n",
    "    \n",
    "    def _load_tree_from_file(self, tree_metadata):\n",
    "        \"\"\"Load a single tree from file.\"\"\"\n",
    "        tree_id = tree_metadata['tree_id']\n",
    "        node_indices = tree_metadata['node_indices']\n",
    "        \n",
    "        if self._file_handle is None:\n",
    "            self._open_file()\n",
    "        \n",
    "        tree_data = {\n",
    "            'tree_id': self._file_handle['tree_id'][node_indices],\n",
    "            'node_index': self._file_handle['node_index'][node_indices],\n",
    "            'parent_index': self._file_handle['parent_index'][node_indices],\n",
    "            'feature_vector': self._file_handle['feature_vector'][node_indices],\n",
    "            'tag': [s.decode('utf-8') for s in self._file_handle['tag'][node_indices]]\n",
    "        }\n",
    "        \n",
    "        nodes = {}\n",
    "        for i in range(len(node_indices)):\n",
    "            node_index = tree_data['node_index'][i]\n",
    "            parent_index = tree_data['parent_index'][i]\n",
    "            feature_vector = tree_data['feature_vector'][i]\n",
    "            if feature_vector.shape[0] != self.expected_dim:\n",
    "                raise ValueError(\n",
    "                    f\"Invalid feature vector dimension for tree_id={tree_id}, \"\n",
    "                    f\"node_index={node_index}: got {feature_vector.shape[0]}, expected {self.expected_dim}\"\n",
    "                )\n",
    "            tag = tree_data['tag'][i]\n",
    "            label = self.label_encoder.transform([tag])[0]\n",
    "            nodes[node_index] = TreeNode(feature_vector, label, node_index, parent_index)\n",
    "        \n",
    "        for node in nodes.values():\n",
    "            if node.parent_index != -1:\n",
    "                parent = nodes.get(node.parent_index)\n",
    "                if parent:\n",
    "                    parent.children.append(node)\n",
    "        \n",
    "        root = next((node for node in nodes.values() if node.parent_index == -1), None)\n",
    "        return root\n",
    "    \n",
    "    def _manage_cache(self, tree_id, tree_data):\n",
    "        \"\"\"Manage LRU cache for trees.\"\"\"\n",
    "        if tree_id in self.cache:\n",
    "            self.cache_order.remove(tree_id)\n",
    "        \n",
    "        self.cache[tree_id] = tree_data\n",
    "        self.cache_order.append(tree_id)\n",
    "        \n",
    "        while len(self.cache) > self.cache_size:\n",
    "            oldest_tree_id = self.cache_order.pop(0)\n",
    "            del self.cache[oldest_tree_id]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.tree_metadata)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        tree_metadata = self.tree_metadata[idx]\n",
    "        tree_id = tree_metadata['tree_id']\n",
    "        \n",
    "        if tree_id in self.cache:\n",
    "            self.cache_order.remove(tree_id)\n",
    "            self.cache_order.append(tree_id)\n",
    "            tree_root = self.cache[tree_id]\n",
    "        else:\n",
    "            tree_root = self._load_tree_from_file(tree_metadata)\n",
    "            self._manage_cache(tree_id, tree_root)\n",
    "        \n",
    "        return {'tree_root': tree_root, 'tree_id': tree_id}\n",
    "\n",
    "def create_tree_metadata(data_path, max_trees=None):\n",
    "    \"\"\"Create metadata for tree structures.\"\"\"\n",
    "    print(f\"Creating tree metadata from {data_path}...\")\n",
    "    \n",
    "    with h5py.File(data_path, 'r') as f:\n",
    "        tree_ids = f['tree_id'][:]\n",
    "        node_indices = f['node_index'][:]\n",
    "        tags = [s.decode('utf-8') for s in f['tag'][:]]\n",
    "        \n",
    "        unique_tree_ids = np.unique(tree_ids)\n",
    "        tree_metadata = []\n",
    "        all_tags = set()\n",
    "        \n",
    "        for tree_id in unique_tree_ids:\n",
    "            tree_node_indices = np.where(tree_ids == tree_id)[0]\n",
    "            tree_metadata.append({\n",
    "                'tree_id': tree_id,\n",
    "                'node_indices': tree_node_indices\n",
    "            })\n",
    "            for idx in tree_node_indices:\n",
    "                all_tags.add(tags[idx])\n",
    "            \n",
    "            if max_trees and len(tree_metadata) >= max_trees:\n",
    "                break\n",
    "    \n",
    "    print(f\"Found {len(tree_metadata)} trees\")\n",
    "    print(f\"Found {len(all_tags)} unique tags\")\n",
    "    return tree_metadata, sorted(list(all_tags))\n",
    "\n",
    "def tree_collate_fn(batch):\n",
    "    \"\"\"Collate function for tree-based dataset.\"\"\"\n",
    "    trees = [item['tree_root'] for item in batch]\n",
    "    tree_ids = [item['tree_id'] for item in batch]\n",
    "    return {'trees': trees, 'tree_ids': tree_ids}\n",
    "\n",
    "class TreeLSTMCell(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim):\n",
    "        super(TreeLSTMCell, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.iou = nn.Linear(input_dim + hidden_dim * 2, 3 * hidden_dim)\n",
    "        self.f = nn.Linear(hidden_dim * 2, hidden_dim)\n",
    "        \n",
    "    def forward(self, x, h_children, c_children):\n",
    "        print(f\"x shape: {x.shape}\")  # Debug\n",
    "        h_sum = sum(h_children) if h_children else torch.zeros(self.hidden_dim * 2).to(device)\n",
    "        print(f\"h_sum shape: {h_sum.shape}\")  # Debug\n",
    "        combined = torch.cat([x, h_sum], dim=-1)\n",
    "        print(f\"Combined input shape: {combined.shape}\")  # Debug\n",
    "        iou = self.iou(combined)\n",
    "        i, o, u = torch.chunk(iou, 3, dim=-1)\n",
    "        i, o, u = torch.sigmoid(i), torch.sigmoid(o), torch.tanh(u)\n",
    "        \n",
    "        f_list = [torch.sigmoid(self.f(h_c)) for h_c in h_children] if h_children else []\n",
    "        c = sum(f * c for f, c in zip(f_list, c_children)) if h_children else torch.zeros_like(u)\n",
    "        c = i * u + c\n",
    "        h = o * torch.tanh(c)\n",
    "        return h, c\n",
    "\n",
    "class TreeBLSTM(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(TreeBLSTM, self).__init__()\n",
    "        self.forward_cell = TreeLSTMCell(input_dim, hidden_dim)\n",
    "        self.backward_cell = TreeLSTMCell(input_dim, hidden_dim)\n",
    "        self.fc = nn.Linear(hidden_dim * 2, output_dim)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "    \n",
    "    def forward(self, tree):\n",
    "        h_forward, c_forward, h_backward, c_backward = self._forward_backward(tree)\n",
    "        h_combined = torch.cat([h_forward, h_backward], dim=-1)\n",
    "        h_combined = self.dropout(h_combined)\n",
    "        logits = self.fc(h_combined)\n",
    "        return logits, h_combined\n",
    "    \n",
    "    def _forward_backward(self, node):\n",
    "        if not node.children:\n",
    "            x = torch.tensor(node.feature_vector, dtype=torch.float32).to(device)\n",
    "            h_f, c_f = self.forward_cell(x, [], [])\n",
    "            h_b, c_b = self.backward_cell(x, [], [])\n",
    "            return h_f, c_f, h_b, c_b\n",
    "        else:\n",
    "            h_children_f = []\n",
    "            c_children_f = []\n",
    "            h_children_b = []\n",
    "            c_children_b = []\n",
    "            \n",
    "            for child in node.children:\n",
    "                h_f, c_f, h_b, c_b = self._forward_backward(child)\n",
    "                h_children_f.append(h_f)\n",
    "                c_children_f.append(c_f)\n",
    "                h_children_b.append(h_b)\n",
    "                c_children_b.append(c_b)\n",
    "            \n",
    "            x = torch.tensor(node.feature_vector, dtype=torch.float32).to(device)\n",
    "            h_f, c_f = self.forward_cell(x, h_children_f, c_children_f)\n",
    "            h_b, c_b = self.backward_cell(x, h_children_b, c_children_b)\n",
    "            return h_f, c_f, h_b, c_b\n",
    "\n",
    "def safe_tree_training_step(model, tree, criterion, optimizer, device):\n",
    "    \"\"\"Safe training step for tree-based model.\"\"\"\n",
    "    try:\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        with autocast():\n",
    "            logits, _ = model(tree)\n",
    "            label = torch.tensor([tree.label], dtype=torch.long).to(device)\n",
    "            loss = criterion(logits, label)\n",
    "        \n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.unscale_(optimizer)\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        \n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "        \n",
    "        return loss.item()\n",
    "    \n",
    "    except RuntimeError as e:\n",
    "        if \"out of memory\" in str(e):\n",
    "            print(f\"WARNING: Out of memory error: {e}\")\n",
    "            if torch.cuda.is_available():\n",
    "                torch.cuda.empty_cache()\n",
    "            return None\n",
    "        else:\n",
    "            raise e\n",
    "\n",
    "def evaluate_tree_model(model, data_loader, criterion, device, label_encoder, phase=\"Validation\"):\n",
    "    \"\"\"Evaluate tree-based model.\"\"\"\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    all_predictions = []\n",
    "    all_labels = []\n",
    "    successful_trees = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        progress_bar = tqdm(data_loader, desc=f\"{phase} Evaluation\")\n",
    "        for batch in progress_bar:\n",
    "            trees = batch['trees']\n",
    "            for tree in trees:\n",
    "                try:\n",
    "                    with autocast():\n",
    "                        logits, _ = model(tree)\n",
    "                        label = torch.tensor([tree.label], dtype=torch.long).to(device)\n",
    "                        loss = criterion(logits, label)\n",
    "                    \n",
    "                    total_loss += loss.item()\n",
    "                    successful_trees += 1\n",
    "                    \n",
    "                    prediction = torch.argmax(logits, dim=1).cpu().numpy()[0]\n",
    "                    label = label.cpu().numpy()[0]\n",
    "                    all_predictions.append(prediction)\n",
    "                    all_labels.append(label)\n",
    "                    \n",
    "                    if torch.cuda.is_available():\n",
    "                        torch.cuda.empty_cache()\n",
    "                    \n",
    "                    progress_bar.set_postfix({\n",
    "                        'loss': f'{loss.item():.4f}',\n",
    "                        'mem': f'{print_memory_usage(printing=False):.1f}GB'\n",
    "                    })\n",
    "                \n",
    "                except RuntimeError as e:\n",
    "                    if \"out of memory\" in str(e):\n",
    "                        print(f\"Skipping {phase.lower()} tree due to OOM\")\n",
    "                        if torch.cuda.is_available():\n",
    "                            torch.cuda.empty_cache()\n",
    "                        continue\n",
    "                    else:\n",
    "                        raise e\n",
    "    \n",
    "    avg_loss = total_loss / successful_trees if successful_trees > 0 else float('inf')\n",
    "    \n",
    "    if len(all_predictions) > 0:\n",
    "        accuracy = accuracy_score(all_labels, all_predictions)\n",
    "        precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "            all_labels, all_predictions, average='weighted', zero_division=0\n",
    "        )\n",
    "        \n",
    "        precision_pc, recall_pc, f1_pc, support_pc = precision_recall_fscore_support(\n",
    "            all_labels, all_predictions, average=None, zero_division=0, labels=range(len(label_encoder.classes_))\n",
    "        )\n",
    "        \n",
    "        report = classification_report(\n",
    "            all_labels, all_predictions, \n",
    "            target_names=label_encoder.classes_, \n",
    "            zero_division=0,\n",
    "            output_dict=True\n",
    "        )\n",
    "        \n",
    "        metrics = {\n",
    "            'loss': avg_loss,\n",
    "            'accuracy': accuracy,\n",
    "            'precision': precision,\n",
    "            'recall': recall,\n",
    "            'f1': f1,\n",
    "            'precision_per_class': precision_pc,\n",
    "            'recall_per_class': recall_pc,\n",
    "            'f1_per_class': f1_pc,\n",
    "            'support_per_class': support_pc,\n",
    "            'classification_report': report,\n",
    "            'predictions': all_predictions,\n",
    "            'labels': all_labels\n",
    "        }\n",
    "    else:\n",
    "        metrics = {\n",
    "            'loss': avg_loss,\n",
    "            'accuracy': 0.0,\n",
    "            'precision': 0.0,\n",
    "            'recall': 0.0,\n",
    "            'f1': 0.0\n",
    "        }\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, class_names, title=\"Confusion Matrix\", save_path=None):\n",
    "    \"\"\"Plot and save confusion matrix.\"\"\"\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    \n",
    "    plt.figure(figsize=(12, 10))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.yticks(rotation=0)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "        print(f\"Confusion matrix saved to {save_path}\")\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "def plot_training_history(train_losses, val_losses, train_accuracies, val_accuracies, save_path=None):\n",
    "    \"\"\"Plot training history.\"\"\"\n",
    "    epochs = range(1, len(train_losses) + 1)\n",
    "    \n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    \n",
    "    ax1.plot(epochs, train_losses, 'b-', label='Training Loss')\n",
    "    ax1.plot(epochs, val_losses, 'r-', label='Validation Loss')\n",
    "    ax1.set_title('Training and Validation Loss')\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.set_ylabel('Loss')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True)\n",
    "    \n",
    "    ax2.plot(epochs, train_accuracies, 'b-', label='Training Accuracy')\n",
    "    ax2.plot(epochs, val_accuracies, 'r-', label='Validation Accuracy')\n",
    "    ax2.set_title('Training and Validation Accuracy')\n",
    "    ax2.set_xlabel('Epoch')\n",
    "    ax2.set_ylabel('Accuracy')\n",
    "    ax2.legend()\n",
    "    ax2.grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "        print(f\"Training history saved to {save_path}\")\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "def save_detailed_results(metrics, label_encoder, output_dir, phase=\"test\"):\n",
    "    \"\"\"Save detailed evaluation results.\"\"\"\n",
    "    results_path = os.path.join(output_dir, f\"{phase}_results.json\")\n",
    "    \n",
    "    json_metrics = {key: value.tolist() if isinstance(value, np.ndarray) else value \n",
    "                    for key, value in metrics.items() if key not in ['predictions', 'labels']}\n",
    "    json_metrics['class_names'] = label_encoder.classes_.tolist()\n",
    "    \n",
    "    with open(results_path, 'w') as f:\n",
    "        json.dump(json_metrics, f, indent=2)\n",
    "    print(f\"Detailed results saved to {results_path}\")\n",
    "    \n",
    "    if 'precision_per_class' in metrics:\n",
    "        per_class_df = pd.DataFrame({\n",
    "            'class': label_encoder.classes_,\n",
    "            'precision': metrics['precision_per_class'],\n",
    "            'recall': metrics['recall_per_class'],\n",
    "            'f1_score': metrics['f1_per_class'],\n",
    "            'support': metrics['support_per_class']\n",
    "        })\n",
    "        per_class_path = os.path.join(output_dir, f\"{phase}_per_class_metrics.csv\")\n",
    "        per_class_df.to_csv(per_class_path, index=False)\n",
    "        print(f\"Per-class metrics saved to {per_class_path}\")\n",
    "\n",
    "def train_tree_model(data_path, model_config, max_trees=None):\n",
    "    output_dir = './models'\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Remove existing checkpoints\n",
    "    for checkpoint in [\"figma_tree_blstm_model.pt\", \"figma_tree_blstm_final_model.pt\"]:\n",
    "        checkpoint_path = os.path.join(output_dir, checkpoint)\n",
    "        if os.path.exists(checkpoint_path):\n",
    "            os.remove(checkpoint_path)\n",
    "            print(f\"Removed existing checkpoint: {checkpoint_path}\")\n",
    "    \n",
    "    tree_metadata, all_tags = create_tree_metadata(data_path, max_trees)\n",
    "    \n",
    "    label_encoder = LabelEncoder()\n",
    "    label_encoder.fit(all_tags)\n",
    "    num_classes = len(label_encoder.classes_)\n",
    "    \n",
    "    with h5py.File(data_path, 'r') as f:\n",
    "        input_dim = f['feature_vector'][0].shape[0]\n",
    "        print(f\"First feature vector dimension: {input_dim}\")\n",
    "        feature_vectors = f['feature_vector'][:]\n",
    "        dims = np.array([fv.shape[0] for fv in feature_vectors])\n",
    "        unique_dims = np.unique(dims)\n",
    "        print(f\"Unique feature vector dimensions: {unique_dims}\")\n",
    "        if len(unique_dims) > 1:\n",
    "            tree_ids = f['tree_id'][:]\n",
    "            node_indices = f['node_index'][:]\n",
    "            tags = [s.decode('utf-8') for s in f['tag'][:]]\n",
    "            for dim in unique_dims:\n",
    "                count = np.sum(dims == dim)\n",
    "                print(f\"Found {count} feature vectors with dimension {dim}\")\n",
    "            anomalous_indices = np.where(dims != input_dim)[0]\n",
    "            for idx in anomalous_indices:\n",
    "                print(f\"Anomaly: tree_id={tree_ids[idx]}, node_index={node_indices[idx]}, tag={tags[idx]}, dim={dims[idx]}\")\n",
    "            raise ValueError(\"Inconsistent feature vector dimensions in dataset\")\n",
    "    \n",
    "    print(f\"Number of classes: {num_classes}\")\n",
    "    \n",
    "    train_metadata, temp_metadata = train_test_split(tree_metadata, test_size=0.3, random_state=42)\n",
    "    val_metadata, test_metadata = train_test_split(temp_metadata, test_size=0.5, random_state=42)\n",
    "    \n",
    "    print(f\"Train trees: {len(train_metadata)}\")\n",
    "    print(f\"Validation trees: {len(val_metadata)}\")\n",
    "    print(f\"Test trees: {len(test_metadata)}\")\n",
    "    \n",
    "    cache_size = min(50, len(train_metadata) // 4)\n",
    "    \n",
    "    train_dataset = LazyFigmaTreeDataset(data_path, train_metadata, label_encoder, cache_size=cache_size, expected_dim=input_dim)\n",
    "    val_dataset = LazyFigmaTreeDataset(data_path, val_metadata, label_encoder, cache_size=cache_size//2, expected_dim=input_dim)\n",
    "    test_dataset = LazyFigmaTreeDataset(data_path, test_metadata, label_encoder, cache_size=cache_size//2, expected_dim=input_dim)\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=1, shuffle=True, collate_fn=tree_collate_fn)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=1, shuffle=False, collate_fn=tree_collate_fn)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False, collate_fn=tree_collate_fn)\n",
    "    \n",
    "    # Initialize model\n",
    "    model = TreeBLSTM(input_dim=input_dim, hidden_dim=model_config['hidden_dim'], output_dim=num_classes).to(device)\n",
    "    print(f\"Model initialized with input_dim={input_dim}, hidden_dim={model_config['hidden_dim']}\")\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=model_config['learning_rate'])\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=3)\n",
    "    \n",
    "    early_stopping = EarlyStopping(patience=model_config['early_stopping_patience'])\n",
    "    \n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    train_accuracies = []\n",
    "    val_accuracies = []\n",
    "    \n",
    "    print(\"Starting training with tree-based BLSTM...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    for epoch in range(model_config['epochs']):\n",
    "        print(f\"Epoch {epoch+1}/{model_config['epochs']}\")\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        successful_trees = 0\n",
    "        \n",
    "        for batch in tqdm(train_loader, desc=\"Training\"):\n",
    "            trees = batch['trees']\n",
    "            for tree in trees:\n",
    "                loss = safe_tree_training_step(model, tree, criterion, optimizer, device)\n",
    "                if loss is not None:\n",
    "                    train_loss += loss\n",
    "                    successful_trees += 1\n",
    "        \n",
    "        avg_train_loss = train_loss / successful_trees if successful_trees > 0 else float('inf')\n",
    "        \n",
    "        val_metrics = evaluate_tree_model(model, val_loader, criterion, device, label_encoder, \"Validation\")\n",
    "        train_metrics = evaluate_tree_model(model, train_loader, criterion, device, label_encoder, \"Training\")\n",
    "        \n",
    "        train_losses.append(avg_train_loss)\n",
    "        val_losses.append(val_metrics['loss'])\n",
    "        train_accuracies.append(train_metrics['accuracy'])\n",
    "        val_accuracies.append(val_metrics['accuracy'])\n",
    "        \n",
    "        print(f\"Train Loss: {avg_train_loss:.4f}, Train Acc: {train_metrics['accuracy']:.4f}\")\n",
    "        print(f\"Val Loss: {val_metrics['loss']:.4f}, Val Acc: {val_metrics['accuracy']:.4f}\")\n",
    "        \n",
    "        model_path = os.path.join(output_dir, \"figma_tree_blstm_model.pt\")\n",
    "        torch.save({\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'label_encoder': label_encoder,\n",
    "            'model_config': model_config,\n",
    "            'input_dim': input_dim,\n",
    "            'num_classes': num_classes,\n",
    "            'tree_metadata': tree_metadata,\n",
    "            'train_losses': train_losses,\n",
    "            'val_losses': val_losses,\n",
    "            'train_accuracies': train_accuracies,\n",
    "            'val_accuracies': val_accuracies\n",
    "        }, model_path)\n",
    "        \n",
    "        scheduler.step(val_metrics['loss'])\n",
    "        if early_stopping(val_metrics['loss'], model):\n",
    "            print(f\"Early stopping at epoch {epoch+1}\")\n",
    "            break\n",
    "        \n",
    "        gc.collect()\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "    \n",
    "    total_time = time.time() - start_time\n",
    "    print(f\"Training completed in {total_time:.2f} seconds\")\n",
    "    \n",
    "    plot_training_history(train_losses, val_losses, train_accuracies, val_accuracies, \n",
    "                         os.path.join(output_dir, \"training_history.png\"))\n",
    "    \n",
    "    test_metrics = evaluate_tree_model(model, test_loader, criterion, device, label_encoder, \"Test\")\n",
    "    print(f\"Test Accuracy: {test_metrics['accuracy']:.4f}, F1: {test_metrics['f1']:.4f}\")\n",
    "    \n",
    "    save_detailed_results(test_metrics, label_encoder, output_dir, \"test\")\n",
    "    if len(test_metrics['predictions']) > 0:\n",
    "        plot_confusion_matrix(test_metrics['labels'], test_metrics['predictions'], label_encoder.classes_,\n",
    "                             save_path=os.path.join(output_dir, \"test_confusion_matrix.png\"))\n",
    "    \n",
    "    final_model_path = os.path.join(output_dir, \"figma_tree_blstm_final_model.pt\")\n",
    "    torch.save({\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'label_encoder': label_encoder,\n",
    "        'model_config': model_config,\n",
    "        'input_dim': input_dim,\n",
    "        'test_metrics': test_metrics\n",
    "    }, final_model_path)\n",
    "    \n",
    "    train_dataset._close_file()\n",
    "    val_dataset._close_file()\n",
    "    test_dataset._close_file()\n",
    "    \n",
    "    return model, label_encoder, test_metrics\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    model_config = {\n",
    "        'hidden_dim': 128,\n",
    "        'dropout': 0.3,\n",
    "        'learning_rate': 0.001,\n",
    "        'batch_size': 1,\n",
    "        'epochs': 50,\n",
    "        'early_stopping_patience': 10\n",
    "    }\n",
    "    \n",
    "    DATA_PATH = \"figma_dataset_tree_blstm.h5\"  # Use corrected dataset\n",
    "    MAX_TREES = 2000\n",
    "    \n",
    "    model, label_encoder, test_metrics = train_tree_model(DATA_PATH, model_config, max_trees=MAX_TREES)\n",
    "    print(\"Training completed successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
