{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import math\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "semantic_model = SentenceTransformer('all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "body_width = None\n",
    "\n",
    "def extract_semantic_features(node, text_nodes_with_content):\n",
    "    \"\"\"\n",
    "    Calculate the semantic features from the nearest text node.\n",
    "    \n",
    "    Args:\n",
    "    node (dict): Current node being processed\n",
    "    text_nodes_with_content (list): List of text nodes with their x, y coordinates and text content\n",
    "    \n",
    "    Returns:\n",
    "    dict: Semantic feature dictionary\n",
    "    \"\"\"\n",
    "    if not text_nodes_with_content:\n",
    "        return {\n",
    "            \"nearest_text_semantic_vector\": [0] * 384,  # Default zero vector\n",
    "            \"nearest_text_semantic_distance\": 9999999\n",
    "        }\n",
    "    \n",
    "    # Get current node's center coordinates\n",
    "    node_data = node.get(\"node\", {})\n",
    "    x = node_data.get(\"x\", 0) + node_data.get(\"width\", 0) / 2\n",
    "    y = node_data.get(\"y\", 0) + node_data.get(\"height\", 0) / 2\n",
    "    \n",
    "    # Calculate Euclidean distances to all text nodes and find the nearest\n",
    "    min_distance = float('inf')\n",
    "    nearest_text_node = None\n",
    "    \n",
    "    for text_node in text_nodes_with_content:\n",
    "        tx, ty = text_node['x'], text_node['y']\n",
    "        distance = math.sqrt((x - tx)**2 + (y - ty)**2)\n",
    "        \n",
    "        if distance < min_distance:\n",
    "            min_distance = distance\n",
    "            nearest_text_node = text_node\n",
    "    \n",
    "    # If a nearest text node is found, get its semantic embedding\n",
    "    if nearest_text_node and nearest_text_node.get('text'):\n",
    "        # Generate semantic embedding for the text\n",
    "        semantic_vector = semantic_model.encode(nearest_text_node['text'])\n",
    "        \n",
    "        return {\n",
    "            \"nearest_text_semantic_vector\": semantic_vector.tolist(),  # Convert to list for JSON serialization\n",
    "            \"nearest_text_semantic_distance\": min_distance\n",
    "        }\n",
    "    \n",
    "    # Fallback if no meaningful text is found\n",
    "    return {\n",
    "        \"nearest_text_semantic_vector\": [0] * 384,  # Default zero vector\n",
    "        \"nearest_text_semantic_distance\": 9999999\n",
    "    }\n",
    "\n",
    "def color_difference(color1, color2):\n",
    "    \"\"\"\n",
    "    Calculate a perceptual color difference between two RGB colors using \n",
    "    a simplified version of the Delta E formula.\n",
    "    Returns a value between 0 and 1, where 0 means identical and 1 means completely different.\n",
    "    \"\"\"\n",
    "    if not all([color1, color2]):\n",
    "        return 0\n",
    "    \n",
    "    # Extract RGB values\n",
    "    r1, g1, b1 = color1\n",
    "    r2, g2, b2 = color2\n",
    "    \n",
    "    # Calculate Euclidean distance in RGB space (simplified)\n",
    "    distance = math.sqrt((r2-r1)**2 + (g2-g1)**2 + (b2-b1)**2)\n",
    "    \n",
    "    # Normalize to 0-1 range (max possible distance is sqrt(3 * 255^2))\n",
    "    max_distance = math.sqrt(3 * 255**2)\n",
    "    normalized_distance = distance / max_distance\n",
    "    \n",
    "    return normalized_distance\n",
    "\n",
    "def extract_features(node, depth=0, parent_tag=None, sibling_count=0, parent_tag_html=None, prev_sibling_tag=None,parent_height=0, parent_bg_color=None, text_nodes=None):\n",
    "    global body_width\n",
    "    # First pass: Collect text nodes if not provided\n",
    "    if text_nodes is None:\n",
    "        def collect_text_nodes(node):\n",
    "            text_nodes_list = []\n",
    "            # Function to check if a node has meaningful text\n",
    "            def has_meaningful_text(node_data):\n",
    "                return node_data.get('type','') == \"TEXT\"\n",
    "            \n",
    "            node_data = node.get(\"node\", {})\n",
    "            # If this node has meaningful text\n",
    "            if has_meaningful_text(node_data):\n",
    "                text_nodes_list.append({\n",
    "                    'x': node_data.get(\"x\", 0) + node_data.get(\"width\", 0) / 2,\n",
    "                    'y': node_data.get(\"y\", 0) + node_data.get(\"height\", 0) / 2,\n",
    "                    'text': node_data.get('characters', '').strip()\n",
    "                })\n",
    "            \n",
    "            # Recursively check children\n",
    "            for child in node.get(\"children\", []):\n",
    "                text_nodes_list.extend(collect_text_nodes(child))\n",
    "            \n",
    "            return text_nodes_list\n",
    "        \n",
    "        text_nodes = collect_text_nodes(node)\n",
    "    \n",
    "    \n",
    "    features = []\n",
    "    \n",
    "    tag = node.get(\"tag\", \"\")\n",
    "    node_data = node.get(\"node\", {})\n",
    "    node_type = str(node_data.get(\"type\", \"\"))\n",
    "\n",
    "    text = node_data.get(\"characters\", \"\")\n",
    "    text_length = len(text)\n",
    "    word_count = len(text.split()) if text else 0\n",
    "    contains_number = any(ch.isdigit() for ch in text)\n",
    "    contains_special_chars = any(not ch.isalnum() and not ch.isspace() for ch in text)\n",
    "    \n",
    "    children = node.get(\"children\", [])\n",
    "    num_direct_children = len(children)\n",
    "    is_leaf = 1 if num_direct_children == 0 else 0\n",
    "    \n",
    "    # Initialize child tag features\n",
    "    child_1_tag = None\n",
    "    child_2_tag = None\n",
    "    child_3_tag = None\n",
    "    child_1_percent = 0\n",
    "    child_2_percent = 0\n",
    "    child_3_percent = 0\n",
    "    \n",
    "    # Calculate node area\n",
    "    node_width = node_data.get(\"width\", 0)\n",
    "    if not body_width or body_width == 0:\n",
    "        body_width = node_width\n",
    "    node_height = node_data.get(\"height\", 0)\n",
    "    node_area = node_width * node_height\n",
    "    \n",
    "    # Extract child information if available\n",
    "    if num_direct_children > 0:\n",
    "        # Child 1\n",
    "        if len(children) >= 1:\n",
    "            child_1_tag = children[0].get(\"tag\", \"\")\n",
    "            child_1_width = children[0].get(\"node\", {}).get(\"width\", 0)\n",
    "            child_1_height = children[0].get(\"node\", {}).get(\"height\", 0)\n",
    "            child_1_area = child_1_width * child_1_height\n",
    "            child_1_percent = (child_1_area / node_area) if node_area > 0 else 0\n",
    "        \n",
    "        # Child 2\n",
    "        if len(children) >= 2:\n",
    "            child_2_tag = children[1].get(\"tag\", \"\")\n",
    "            child_2_width = children[1].get(\"node\", {}).get(\"width\", 0)\n",
    "            child_2_height = children[1].get(\"node\", {}).get(\"height\", 0)\n",
    "            child_2_area = child_2_width * child_2_height\n",
    "            child_2_percent = (child_2_area / node_area) if node_area > 0 else 0\n",
    "        \n",
    "        # Child 3\n",
    "        if len(children) >= 3:\n",
    "            child_3_tag = children[2].get(\"tag\", \"\")\n",
    "            child_3_width = children[2].get(\"node\", {}).get(\"width\", 0)\n",
    "            child_3_height = children[2].get(\"node\", {}).get(\"height\", 0)\n",
    "            child_3_area = child_3_width * child_3_height\n",
    "            child_3_percent = (child_3_area / node_area) if node_area > 0 else 0\n",
    "    \n",
    "    # Count all children in the subtree (recursive count)\n",
    "    def count_all_descendants(node):\n",
    "        count = 0\n",
    "        for child in node.get(\"children\", []):\n",
    "            # Count this child\n",
    "            count += 1\n",
    "            # Add all its descendants\n",
    "            count += count_all_descendants(child)\n",
    "        return count\n",
    "    \n",
    "    # Count chars to the end\n",
    "    def count_chars_to_end(node):\n",
    "        count = 0\n",
    "        for child in node.get(\"children\", []):\n",
    "            # Count this child\n",
    "            node_data = child.get(\"node\", {})\n",
    "            count += len(node_data.get(\"characters\", \"\"))\n",
    "            # Add all its descendants\n",
    "            count += count_chars_to_end(child)\n",
    "        return count\n",
    "    \n",
    "    # get center of weight\n",
    "    def get_center_of_weight(node):\n",
    "        total_area = 0\n",
    "        total = 0\n",
    "        for child in node.get(\"children\", []):\n",
    "            node_data = child.get(\"node\", {})\n",
    "            x_center = node_data.get(\"x\",0) + node_data.get(\"width\",0) / 2\n",
    "            area = node_data.get(\"width\",0) * node_data.get(\"height\",0)\n",
    "            total += area * x_center\n",
    "            total_area += area\n",
    "        weighted_x = total/(total_area if total_area else 1)\n",
    "        diff = abs(node.get('x',0)-weighted_x) / (node.get('width',0) if node.get('width',0) else 1)\n",
    "        return diff if node.get('width',0) else 9999999\n",
    "    \n",
    "    # Calculate total descendants\n",
    "    num_children_to_end = count_all_descendants(node)\n",
    "    chars_count_to_end = count_chars_to_end(node)\n",
    "    bg_color = None\n",
    "    feature = {\n",
    "        \"tag\": tag,\n",
    "        \"type\": node_type,\n",
    "        \"x\": node_data.get(\"x\", 0),\n",
    "        \"y\": node_data.get(\"y\", 0),\n",
    "        \"width\": node_width/(body_width if body_width else 1),\n",
    "        \"height\": node_height/(parent_height if parent_height else node_height if node_height else 1),\n",
    "        \"characters\": text,\n",
    "        \"has_text\": int(bool(text)),\n",
    "        \"depth\": depth,\n",
    "        \"num_direct_children\": num_direct_children,\n",
    "        \"num_children_to_end\": num_children_to_end,  # Total descendants count\n",
    "        \"parent_tag\": parent_tag if parent_tag else \"\",\n",
    "        \"parent_tag_html\": parent_tag_html if parent_tag_html else \"\",\n",
    "        \"sibling_count\": sibling_count,\n",
    "        \"prev_sibling_html_tag\": prev_sibling_tag if prev_sibling_tag else \"\",\n",
    "        \"is_leaf\": is_leaf,\n",
    "        \"font_size\": node_data.get(\"fontSize\", 16),\n",
    "        \"has_font_size\": int(\"fontSize\" in node_data),\n",
    "        \"font_name\": node_data.get(\"fontName\", {}).get(\"style\", \"\") if node_data.get(\"fontName\") else \"normal\",\n",
    "        \"has_text_color\": 0, \"color_r\": 0, \"color_g\": 0, \"color_b\": 0,\n",
    "        \"has_background_color\": 0, \"background_r\": 0, \"background_g\": 0, \"background_b\": 0,\n",
    "        \"border_radius\": 0,\n",
    "        \"border_r\": 0, \"border_g\": 0, \"border_b\": 0,\n",
    "        \"has_border\": 0, \"border_opacity\": 0,\n",
    "        \"border_weight\": node_data.get(\"strokeWeight\", 0),\n",
    "        \"has_shadow\": 0, \"shadow_r\": 0, \"shadow_g\": 0, \"shadow_b\": 0,\n",
    "        \"shadow_radius\": 0, \n",
    "        \"text_length\": text_length,\n",
    "        \"chars_count_to_end\": chars_count_to_end,\n",
    "        \"word_count\": word_count,\n",
    "        \"contains_number\": int(contains_number),\n",
    "        \"contains_special_chars\": int(contains_special_chars),\n",
    "        \"aspect_ratio\": node_width / node_height if node_height > 0 else 0,\n",
    "        \"child_1_html_tag\": child_1_tag,\n",
    "        \"child_2_html_tag\": child_2_tag,\n",
    "        \"child_3_html_tag\": child_3_tag,\n",
    "        \"child_1_percentage_of_parent\": child_1_percent,\n",
    "        \"child_2_percentage_of_parent\": child_2_percent,\n",
    "        \"child_3_percentage_of_parent\": child_3_percent,\n",
    "        \"distinct_background\": 0,\n",
    "        \"center_of_weight_diff\": get_center_of_weight(node),\n",
    "    }\n",
    "    \n",
    "    # Extract fills (background and text color)\n",
    "    fills = node_data.get(\"fills\", [])\n",
    "    for fill in fills:\n",
    "        if fill.get(\"type\") == \"SOLID\" and \"color\" in fill:\n",
    "            r, g, b = (\n",
    "                int(fill[\"color\"].get(\"r\", 0) * 255),\n",
    "                int(fill[\"color\"].get(\"g\", 0) * 255),\n",
    "                int(fill[\"color\"].get(\"b\", 0) * 255),\n",
    "            )\n",
    "            feature[\"color_r\"], feature[\"color_g\"], feature[\"color_b\"] = r, g, b\n",
    "            feature[\"has_text_color\"] = 1  # Flag indicating explicit text color is set\n",
    "            \n",
    "            feature[\"background_r\"], feature[\"background_g\"], feature[\"background_b\"] = r, g, b\n",
    "            feature[\"has_background_color\"] = 1  # Flag for explicit background color\n",
    "            a = min(float(fill[\"color\"].get(\"a\", 1)),float(fill.get(\"opacity\",1)))\n",
    "            \n",
    "            bg_color = (r*a, g*a, b*a)\n",
    "            check = \"NO\"\n",
    "            if parent_bg_color:\n",
    "                bg_difference = color_difference(bg_color, parent_bg_color)               \n",
    "                # If difference is significant (threshold of 0.3 - adjust as needed)\n",
    "                if bg_difference > 0.2:\n",
    "                    feature[\"distinct_background\"] = 1    \n",
    "            break\n",
    "    \n",
    "    # Also check backgrounds for background color\n",
    "    backgrounds = node_data.get(\"backgrounds\", [])\n",
    "    for bg in backgrounds:\n",
    "        if bg.get(\"type\") == \"SOLID\" and \"color\" in bg:\n",
    "            r, g, b = (\n",
    "                int(bg[\"color\"].get(\"r\", 0) * 255),\n",
    "                int(bg[\"color\"].get(\"g\", 0) * 255),\n",
    "                int(bg[\"color\"].get(\"b\", 0) * 255),\n",
    "            )\n",
    "            feature[\"background_r\"], feature[\"background_g\"], feature[\"background_b\"] = r, g, b\n",
    "            feature[\"has_background_color\"] = 1  # Flag for explicit background color\n",
    "            \n",
    "           \n",
    "                \n",
    "            break\n",
    "    \n",
    "    # Extract strokes (borders)\n",
    "    strokes = node_data.get(\"strokes\", [])\n",
    "    if strokes:\n",
    "        stroke = strokes[0]\n",
    "        feature[\"has_border\"] = 1\n",
    "        if \"color\" in stroke:\n",
    "            feature[\"border_r\"], feature[\"border_g\"], feature[\"border_b\"] = (\n",
    "                int(stroke[\"color\"].get(\"r\", 0) * 255),\n",
    "                int(stroke[\"color\"].get(\"g\", 0) * 255),\n",
    "                int(stroke[\"color\"].get(\"b\", 0) * 255),\n",
    "            )\n",
    "        feature[\"border_opacity\"] = stroke.get(\"opacity\", 0)\n",
    "    \n",
    "    # Extract border radius\n",
    "    br_top_left = node_data.get(\"topLeftRadius\", 0)\n",
    "    br_top_right = node_data.get(\"topRightRadius\", 0)\n",
    "    br_bottom_left = node_data.get(\"bottomLeftRadius\", 0)\n",
    "    br_bottom_right = node_data.get(\"bottomRightRadius\", 0)\n",
    "    \n",
    "    if any([br_top_left, br_top_right, br_bottom_left, br_bottom_right]):\n",
    "        feature[\"border_radius\"] = (br_top_left + br_top_right + br_bottom_left + br_bottom_right) / 4\n",
    "        if feature[\"border_radius\"] >= 50:\n",
    "            feature[\"border_radius\"] = 0\n",
    "    \n",
    "    # Extract shadow\n",
    "    effects = node_data.get(\"effects\", [])\n",
    "    for effect in effects:\n",
    "        if effect.get(\"type\") == \"DROP_SHADOW\":\n",
    "            feature[\"has_shadow\"] = 1\n",
    "            if \"color\" in effect:\n",
    "                feature[\"shadow_r\"], feature[\"shadow_g\"], feature[\"shadow_b\"] = (\n",
    "                    int(effect[\"color\"].get(\"r\", 0) * 255),\n",
    "                    int(effect[\"color\"].get(\"g\", 0) * 255),\n",
    "                    int(effect[\"color\"].get(\"b\", 0) * 255),\n",
    "                )\n",
    "            feature[\"shadow_radius\"] = effect.get(\"radius\", 0)\n",
    "            break  \n",
    "    \n",
    "    # Get semantic features for the current node\n",
    "    semantic_features = extract_semantic_features(node, text_nodes)\n",
    "    \n",
    "    # Calculate nearest text node distance\n",
    "    nearest_text_distance = semantic_features.get('nearest_text_semantic_distance',0)\n",
    "    nearest_text_semantic = semantic_features.get('nearest_text_semantic_vector',[0]*384)\n",
    "    \n",
    "    # Add nearest text node distance to the feature dictionary\n",
    "    feature[\"nearest_text_node_dist\"] = (nearest_text_distance) / (math.sqrt((node_width)* (node_height)) if math.sqrt((node_width)*(node_height)) else 1)\n",
    "    feature[\"nearest_text_semantic\"] = nearest_text_semantic\n",
    "    features.append(feature)\n",
    "    \n",
    "    # Process children with previous sibling information\n",
    "    prev_sib_tag = None\n",
    "    for child in children:\n",
    "        features.extend(extract_features(\n",
    "            child, \n",
    "            depth=depth+1, \n",
    "            parent_tag=node_type, \n",
    "            sibling_count=len(children)-1, \n",
    "            parent_tag_html=tag,\n",
    "            prev_sibling_tag=prev_sib_tag,\n",
    "            parent_height= node_height,\n",
    "            parent_bg_color=bg_color if feature[\"has_background_color\"] else parent_bg_color,\n",
    "            text_nodes=text_nodes\n",
    "        ))\n",
    "        prev_sib_tag = child.get(\"tag\", \"\")\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Folder containing JSON files\n",
    "data_folder = \"../json_data\"\n",
    "output_csv_file = \"figma_dataset.csv\"\n",
    "\n",
    "normalize_columns = [\n",
    "    # \"area\",\n",
    "    # \"word_count\",\n",
    "    # \"text_length\",\n",
    "    # \"font_size\",\n",
    "    # \"sibling_count\",\n",
    "    # \"num_children\",\n",
    "    # \"height\",\n",
    "    # \"width\",\n",
    "    # \"depth\",\n",
    "    # \"nearest_text_node_dist\"\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "# If the output CSV exists, remove it so we start fresh\n",
    "if os.path.exists(output_csv_file):\n",
    "    os.remove(output_csv_file)\n",
    "\n",
    "# Flag to write header only for the first batch\n",
    "first_batch = True\n",
    "\n",
    "# Iterate over all JSON files in the data folder\n",
    "for filename in os.listdir(data_folder):\n",
    "    if filename.endswith(\".json\"):\n",
    "        file_path = os.path.join(data_folder, filename)\n",
    "        print(f\"Processing {file_path}...\")\n",
    "        \n",
    "        with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "            data = json.load(file)\n",
    "        \n",
    "        # Extract features using the recursive function starting at the root\n",
    "        features_list = extract_features(data, depth=0, parent_tag=None, sibling_count=0, parent_tag_html=None, parent_height= 0, parent_bg_color=None)\n",
    "        if not features_list:\n",
    "            continue  # Skip if no features extracted\n",
    "        \n",
    "        df = pd.DataFrame(features_list)\n",
    "\n",
    "        df = df.drop(columns=['x'])\n",
    "        df = df.drop(columns=['y'])\n",
    "        df = df.drop(columns=['characters'])\n",
    "        df = df.drop(columns=['font_size'])\n",
    "        df = df.drop(columns=['font_name'])\n",
    "        df = df.drop(columns=['color_r'])\n",
    "        df = df.drop(columns=['color_g'])\n",
    "        df = df.drop(columns=['color_b'])\n",
    "        df = df.drop(columns=['background_r'])\n",
    "        df = df.drop(columns=['background_g'])\n",
    "        df = df.drop(columns=['background_b'])\n",
    "        # df = df.drop(columns=['border_radius'])\n",
    "        df = df.drop(columns=['border_r'])\n",
    "        df = df.drop(columns=['border_g'])\n",
    "        df = df.drop(columns=['border_b'])\n",
    "        df = df.drop(columns=['border_opacity'])\n",
    "        df = df.drop(columns=['border_weight'])\n",
    "        df = df.drop(columns=['shadow_r'])\n",
    "        df = df.drop(columns=['shadow_g'])\n",
    "        df = df.drop(columns=['shadow_b'])\n",
    "        df = df.drop(columns=['shadow_radius'])\n",
    "        df = df.drop(columns=['word_count'])\n",
    "        df = df.drop(columns=['contains_special_chars'])\n",
    "        df = df.drop(columns=['contains_number'])\n",
    "        df = df.drop(columns=['has_shadow'])\n",
    "        df = df.drop(columns=['has_border'])\n",
    "        df = df.drop(columns=['has_text_color'])\n",
    "        # df = df.drop(columns=['height'])\n",
    "        df = df.drop(columns=['has_text'])\n",
    "        df = df.drop(columns=['depth'])\n",
    "        df = df.drop(columns=['has_font_size'])\n",
    "        df = df.drop(columns=['parent_tag'])\n",
    "        df = df.drop(columns=['parent_tag_html'])\n",
    "        df = df.drop(columns=['is_leaf'])\n",
    "        df = df.drop(columns=['center_of_weight_diff'])\n",
    "        df = df.drop(columns=['child_3_html_tag'])\n",
    "        df = df.drop(columns=['child_3_percentage_of_parent'])\n",
    "        df = df.drop(columns=['num_direct_children'])\n",
    "\n",
    "\n",
    "        df.to_csv(output_csv_file, mode='a', header=first_batch, index=False)\n",
    "        first_batch = False\n",
    "\n",
    "print(f\"Extracted features from all JSON files have been saved to {output_csv_file}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
